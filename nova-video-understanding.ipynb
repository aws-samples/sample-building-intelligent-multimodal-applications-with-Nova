{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe8d615b-fa47-485b-9dc3-13fe1937d04f",
   "metadata": {},
   "source": [
    "# Video Understanding with Amazon Nova Omni\n",
    "\n",
    "This notebook demonstrates the comprehensive video analysis capabilities of Amazon Nova Omni model, showcasing five distinct capabilities: video summarization, temporal event detection, structured action timeline generation, content moderation, and logo recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a1c8d4-c1d1-412e-ad89-984066da48bc",
   "metadata": {},
   "source": [
    "## What You'll Learn\n",
    "\n",
    "In this notebook, you will explore how Amazon Nova Omni analyzes video content across multiple dimensions:\n",
    "\n",
    "1. **Video Summarization** - Generate concise summaries of video content\n",
    "2. **Structured Action Timeline** - Create JSON-formatted chronological action lists\n",
    "3. **Content Moderation** - Detect explicit visual and toxic audio content\n",
    "4. **Logo Recognition** - Identify brand logos and trademarks in video frames\n",
    "\n",
    "You'll also learn how to:\n",
    "- Process video content using S3 URI references\n",
    "- Track API costs for each model invocation\n",
    "- Generate structured outputs for programmatic processing\n",
    "- Handle errors gracefully during video analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5e4ef-f296-48cd-943b-6b2b3701daf8",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Let's begin by setting up our environment with the necessary dependencies and configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d75138-3ed9-4650-9f72-d41f9072e83a",
   "metadata": {},
   "source": [
    "### Import Required Dependencies\n",
    "\n",
    "First, let's import all necessary Python packages for handling video and AWS services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48b563d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sagemaker\n",
    "from botocore.config import Config\n",
    "from IPython.display import Video\n",
    "from botocore.exceptions import ClientError, NoCredentialsError, PartialCredentialsError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d4061-c854-45f2-bf9f-89c59650d80a",
   "metadata": {},
   "source": [
    "### Initialize AWS Service Clients\n",
    "\n",
    "Next, we'll initialize boto3 clients for S3 and Bedrock services, and configure our AWS environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure AWS environment\n",
    "REGION_ID = \"us-west-2\"\n",
    "MODEL_ID = \"us.amazon.nova-2-omni-v1:0\"\n",
    "BEDROCK_ENDPOINT_URL = \"https://bedrock-runtime.us-west-2.amazonaws.com\"\n",
    "\n",
    "READ_TIMEOUT_SEC = 3 * 60\n",
    "MAX_RETRIES = 1\n",
    "\n",
    "import boto3\n",
    "import base64\n",
    "import json\n",
    "import timeit\n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import Image, display\n",
    "from botocore.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e65b3b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ AWS clients initialized successfully\n",
      "✓ Region: us-west-2\n",
      "✓ Account ID: 149536455198\n"
     ]
    }
   ],
   "source": [
    "# Create a SageMaker session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "def get_bedrock_runtime():\n",
    "    \"\"\"Returns a Bedrock Runtime client.\"\"\"\n",
    "    # Create Bedrock client\n",
    "    config = Config(\n",
    "        read_timeout=READ_TIMEOUT_SEC,\n",
    "        retries={\"max_attempts\": MAX_RETRIES},\n",
    "    )\n",
    "    \n",
    "    bedrock = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=REGION_ID,\n",
    "        config=config,\n",
    "    )\n",
    "    return bedrock\n",
    "\n",
    "try:\n",
    "    boto3.setup_default_session(region_name=REGION_ID)\n",
    "    \n",
    "    # Initialize AWS service clients\n",
    "    sts_client = boto3.client(\"sts\")\n",
    "    account_id = sts_client.get_caller_identity().get(\"Account\")\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    bedrock_client = get_bedrock_runtime()\n",
    "    \n",
    "    print(f\"✓ AWS clients initialized successfully\")\n",
    "    print(f\"✓ Region: {REGION_ID}\")\n",
    "    print(f\"✓ Account ID: {account_id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error during AWS initialization: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe2e69f-13e2-4f26-ab9d-98e88735181d",
   "metadata": {},
   "source": [
    "### Configure S3 Bucket and Model Settings\n",
    "\n",
    "Define the S3 bucket for video storage and the Nova Omni model identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073c334-37a8-4fdc-9c65-c54a47496e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model ID: us.amazon.nova-2-lite-omni-v1:0\n",
      "✓ S3 Bucket: sagemaker-us-west-2-149536455198\n",
      "✓ Video Subfolder: video_understanding/\n",
      "✓ S3 bucket access validated successfully\n"
     ]
    }
   ],
   "source": [
    "# Define the model ID for Amazon Nova Omni\n",
    "MODEL_ID = \"us.amazon.nova-2-omni-v1:0\"\n",
    "\n",
    "# Get the default S3 bucket name and subfolder for video storage\n",
    "BUCKET_NAME = sess.default_bucket()\n",
    "VIDEO_SUBFOLDER = \"video_understanding/\"\n",
    "\n",
    "print(f\"✓ Model ID: {MODEL_ID}\")\n",
    "print(f\"✓ S3 Bucket: {BUCKET_NAME}\")\n",
    "print(f\"✓ Video Subfolder: {VIDEO_SUBFOLDER}\")\n",
    "\n",
    "# Validate S3 bucket access\n",
    "try:\n",
    "    s3_client.head_bucket(Bucket=BUCKET_NAME)\n",
    "    print(f\"✓ S3 bucket access validated successfully\")\n",
    "except ClientError as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code == '404':\n",
    "        print(f\"✗ Error: S3 bucket '{BUCKET_NAME}' does not exist.\")\n",
    "        print(\"  Please create the bucket or update BUCKET_NAME to an existing bucket.\")\n",
    "    elif error_code == '403':\n",
    "        print(f\"✗ Error: Access denied to S3 bucket '{BUCKET_NAME}'.\")\n",
    "        print(\"  Please check your IAM permissions for S3 access.\")\n",
    "    else:\n",
    "        print(f\"✗ AWS Error [{error_code}]: {e.response['Error']['Message']}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error validating S3 bucket access: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf70c8c-493b-4700-910f-cde4527601e7",
   "metadata": {},
   "source": [
    "### Define Helper Functions\n",
    "\n",
    "Let's create reusable helper functions for video upload, model invocation, cost calculation, and result display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27524616-2864-4d92-86be-b999e7d47ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_video_to_s3(local_path, bucket_name, s3_key, s3_client):\n",
    "    \"\"\"\n",
    "    Upload a video file to S3 and return its URI.\n",
    "    \n",
    "    Args:\n",
    "        local_path (str): Local file path to video\n",
    "        bucket_name (str): Target S3 bucket\n",
    "        s3_key (str): S3 object key (path within bucket)\n",
    "        s3_client: Initialized S3 client\n",
    "        \n",
    "    Returns:\n",
    "        str: S3 URI in format s3://bucket/key\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If the local video file doesn't exist\n",
    "        ClientError: If S3 upload fails due to AWS service errors\n",
    "        Exception: For other unexpected errors\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input parameters\n",
    "        if not local_path:\n",
    "            raise ValueError(\"local_path cannot be empty\")\n",
    "        if not bucket_name:\n",
    "            raise ValueError(\"bucket_name cannot be empty\")\n",
    "        if not s3_key:\n",
    "            raise ValueError(\"s3_key cannot be empty\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(local_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"Video file not found: {local_path}\\n\"\n",
    "                f\"  Please verify the file path and ensure the video file exists.\"\n",
    "            )\n",
    "        \n",
    "        # Check if file is readable\n",
    "        if not os.access(local_path, os.R_OK):\n",
    "            raise PermissionError(\n",
    "                f\"Cannot read video file: {local_path}\\n\"\n",
    "                f\"  Please check file permissions.\"\n",
    "            )\n",
    "        \n",
    "        # Get file size for validation\n",
    "        file_size = os.path.getsize(local_path)\n",
    "        if file_size == 0:\n",
    "            raise ValueError(f\"Video file is empty: {local_path}\")\n",
    "        \n",
    "        print(f\"  Uploading {os.path.basename(local_path)} ({file_size:,} bytes)...\")\n",
    "        \n",
    "        # Upload file to S3\n",
    "        s3_client.upload_file(local_path, bucket_name, s3_key)\n",
    "        \n",
    "        # Verify upload by checking if object exists\n",
    "        try:\n",
    "            s3_client.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "        except ClientError:\n",
    "            raise RuntimeError(\n",
    "                f\"Upload appeared to succeed but object not found in S3: {s3_key}\\n\"\n",
    "                f\"  This may indicate a transient error. Please try again.\"\n",
    "            )\n",
    "        \n",
    "        # Generate S3 URI\n",
    "        s3_uri = f\"s3://{bucket_name}/{s3_key}\"\n",
    "        \n",
    "        print(f\"✓ Successfully uploaded {os.path.basename(local_path)} to S3\")\n",
    "        print(f\"  URI: {s3_uri}\")\n",
    "        \n",
    "        return s3_uri\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"✗ File Error: {e}\")\n",
    "        raise\n",
    "    except PermissionError as e:\n",
    "        print(f\"✗ Permission Error: {e}\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        print(f\"✗ Validation Error: {e}\")\n",
    "        raise\n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        error_message = e.response['Error']['Message']\n",
    "        print(f\"✗ AWS S3 Error [{error_code}]: {error_message}\")\n",
    "        if error_code == 'NoSuchBucket':\n",
    "            print(f\"  The bucket '{bucket_name}' does not exist.\")\n",
    "        elif error_code == 'AccessDenied':\n",
    "            print(f\"  Access denied. Please check your IAM permissions for s3:PutObject.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Unexpected error during S3 upload: {str(e)}\")\n",
    "        print(f\"  File: {local_path}\")\n",
    "        print(f\"  Bucket: {bucket_name}\")\n",
    "        print(f\"  Key: {s3_key}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be92bfd5-b5d7-4248-bf8d-8a25dfbe5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_nova_video(video_uri, prompt, temperature=0.3, bedrock_client=None):\n",
    "    \"\"\"\n",
    "    Invoke Nova Omni model with video content.\n",
    "    \n",
    "    Args:\n",
    "        video_uri (str): S3 URI of video file\n",
    "        prompt (str): User prompt for analysis\n",
    "        temperature (float): Model temperature parameter\n",
    "        bedrock_client: Initialized Bedrock client\n",
    "\n",
    "    Returns:\n",
    "        tuple: (full_response, content_text)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If required parameters are invalid\n",
    "        ClientError: If Bedrock API call fails\n",
    "        KeyError: If response format is unexpected\n",
    "        Exception: For other unexpected errors\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input parameters\n",
    "        if not video_uri:\n",
    "            raise ValueError(\"video_uri cannot be empty\")\n",
    "        if not prompt:\n",
    "            raise ValueError(\"prompt cannot be empty\")\n",
    "        if not video_uri.startswith('s3://'):\n",
    "            raise ValueError(f\"Invalid S3 URI format: {video_uri}. Must start with 's3://'\")\n",
    "        if bedrock_client is None:\n",
    "            raise ValueError(\"bedrock_client cannot be None\")\n",
    "        if not isinstance(temperature, (int, float)) or temperature < 0 or temperature > 1:\n",
    "            raise ValueError(f\"temperature must be between 0 and 1, got: {temperature}\")\n",
    "        \n",
    "        # Format user message with video and prompt\n",
    "        request = {\n",
    "            \"modelId\": MODEL_ID,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"video\": {\n",
    "                                \"format\": \"mp4\",\n",
    "                                \"source\": {\n",
    "                                    \"s3Location\": {\n",
    "                                        \"uri\": video_uri\n",
    "                                    }\n",
    "                                },\n",
    "                            }\n",
    "                        },\n",
    "                        {\"text\": prompt},\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            \"inferenceConfig\": {\"temperature\": temperature, \"topP\": 0.95, \"maxTokens\": 10000},\n",
    "        }\n",
    "        \n",
    "        # Invoke the model\n",
    "        response = bedrock_client.converse(**request)\n",
    "        \n",
    "        # Validate response structure\n",
    "        if \"output\" not in response:\n",
    "            raise KeyError(\"Response missing 'output' field\")\n",
    "        if \"message\" not in response[\"output\"]:\n",
    "            raise KeyError(\"Response missing 'output.message' field\")\n",
    "        if \"content\" not in response[\"output\"][\"message\"]:\n",
    "            raise KeyError(\"Response missing 'output.message.content' field\")\n",
    "        \n",
    "        response_content_list = response[\"output\"][\"message\"][\"content\"]\n",
    "        \n",
    "        if not response_content_list:\n",
    "            raise ValueError(\"Response content is empty\")\n",
    "        \n",
    "        # Extract text content block\n",
    "        text_content = next(\n",
    "            (item for item in response_content_list if \"text\" in item),\n",
    "            None,\n",
    "        )\n",
    "\n",
    "        content_text = \"\"\n",
    "        if text_content:\n",
    "            print(\"== Text Output ==\")\n",
    "            content_text = text_content[\"text\"]\n",
    "            print(content_text)\n",
    "        \n",
    "        return response, content_text\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"✗ Validation Error: {e}\")\n",
    "        raise\n",
    "    except KeyError as e:\n",
    "        print(f\"✗ Response Format Error: {e}\")\n",
    "        print(\"  The model response structure was unexpected.\")\n",
    "        print(f\"  Response keys: {list(response.keys()) if 'response' in locals() else 'N/A'}\")\n",
    "        raise\n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        error_message = e.response['Error']['Message']\n",
    "        print(f\"✗ AWS Bedrock Error [{error_code}]: {error_message}\")\n",
    "        if error_code == 'AccessDeniedException':\n",
    "            print(\"  Please check your IAM permissions for bedrock:InvokeModel.\")\n",
    "        elif error_code == 'ResourceNotFoundException':\n",
    "            print(f\"  The model '{MODEL_ID}' may not be available in region '{REGION_ID}'.\")\n",
    "            print(\"  Please verify model availability and enable it in the Bedrock console.\")\n",
    "        elif error_code == 'ValidationException':\n",
    "            print(\"  The request parameters may be invalid.\")\n",
    "            print(f\"  Video URI: {video_uri}\")\n",
    "        elif error_code == 'ThrottlingException':\n",
    "            print(\"  Request rate exceeded. Please wait and try again.\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"✗ JSON Parsing Error: {e}\")\n",
    "        print(\"  Failed to parse model response as JSON.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Unexpected error during model invocation: {str(e)}\")\n",
    "        print(f\"  Video URI: {video_uri}\")\n",
    "        print(f\"  Model ID: {MODEL_ID}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf70c33d-167b-4217-b2f1-c0b94c299651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_response(content_text, show_full_response=False, full_response=None):\n",
    "    \"\"\"\n",
    "    Display formatted model response.\n",
    "    \n",
    "    Args:\n",
    "        content_text (str): Extracted text content from response\n",
    "        show_full_response (bool): Whether to show full JSON response\n",
    "        full_response (dict): Full model response dictionary\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESPONSE CONTENT\")\n",
    "    print(\"=\"*80)\n",
    "    print(content_text)\n",
    "    \n",
    "    if show_full_response and full_response:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FULL JSON RESPONSE\")\n",
    "        print(\"=\"*80)\n",
    "        print(json.dumps(full_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "61666906-f51a-4299-ab8d-4b65687fc934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_response(content_text):\n",
    "    \"\"\"\n",
    "    Parse JSON from model response, handling code blocks.\n",
    "    \n",
    "    Args:\n",
    "        content_text (str): Text content from model response\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parsed JSON data\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If content_text is empty or None\n",
    "        json.JSONDecodeError: If JSON parsing fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input\n",
    "        if not content_text:\n",
    "            raise ValueError(\"content_text cannot be empty or None\")\n",
    "        \n",
    "        # Remove code block markers if present\n",
    "        json_text = content_text.strip()\n",
    "        \n",
    "        # Handle various markdown code block formats\n",
    "        if json_text.startswith(\"```json\"):\n",
    "            json_text = json_text.replace(\"```json\", \"\", 1)\n",
    "        elif json_text.startswith(\"```\"):\n",
    "            json_text = json_text.replace(\"```\", \"\", 1)\n",
    "        \n",
    "        if json_text.endswith(\"```\"):\n",
    "            json_text = json_text.rsplit(\"```\", 1)[0]\n",
    "        \n",
    "        json_text = json_text.strip()\n",
    "        \n",
    "        # Validate that we have JSON-like content\n",
    "        if not json_text:\n",
    "            raise ValueError(\"No content remaining after removing code block markers\")\n",
    "        \n",
    "        if not (json_text.startswith('{') or json_text.startswith('[')):\n",
    "            raise ValueError(\n",
    "                f\"Content does not appear to be JSON. \"\n",
    "                f\"Expected to start with '{{' or '[', but starts with: {json_text[:50]}...\"\n",
    "            )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(json_text)\n",
    "        \n",
    "        # Validate that we got a dict or list\n",
    "        if not isinstance(data, (dict, list)):\n",
    "            raise ValueError(f\"Parsed JSON is not a dict or list, got: {type(data)}\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"✗ Validation Error: {e}\")\n",
    "        print(f\"\\nRaw response (first 500 chars):\\n{content_text[:500]}...\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"✗ JSON Parsing Error: {e}\")\n",
    "        print(f\"  Line {e.lineno}, Column {e.colno}: {e.msg}\")\n",
    "        print(f\"\\nProblematic JSON text (first 500 chars):\\n{json_text[:500]}...\")\n",
    "        print(\"\\nThe model may have returned text instead of pure JSON.\")\n",
    "        print(\"Consider adjusting the prompt to request JSON-only output.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Unexpected error parsing JSON: {str(e)}\")\n",
    "        print(f\"\\nRaw response (first 500 chars):\\n{content_text[:500]}...\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea5e7d-8385-464c-8501-679d146ffa61",
   "metadata": {},
   "source": [
    "## Video Upload to S3\n",
    "\n",
    "Now let's upload our test videos to S3 so that Nova Omni can access them via S3 URIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110e375",
   "metadata": {},
   "source": [
    "### About Our Sample Videos\n",
    "\n",
    "For this demonstration, we'll use video files:\n",
    "\n",
    "1. **Meridian_Clip.mp4** - A clip from \"Meridian,\" a short film from Netflix Open Content featuring a vintage car on a mountain road\n",
    "2. **the-sea.mp4** - A video depicting sea scenery\n",
    "3. **Andy-Jassy-on-Amazon-Nova.mp4** - Amazon CEO Andy Jassy talks about Amazon Nova models\n",
    "4. **Cheesecake.mp4** - A video depicting how to make a cheesecase\n",
    "\n",
    "These videos will be uploaded to the S3 bucket in the `video_understanding/` subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "video-discovery-upload",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovering videos in media directory...\n",
      "\n",
      "Found 4 video file(s):\n",
      "  - Andy-Jassy-on-Amazon-Nova.mp4 (43,646,472 bytes)\n",
      "  - Cheesecake.mp4 (11,080,848 bytes)\n",
      "  - Meridian_Clip.mp4 (5,504,861 bytes)\n",
      "  - the-sea.mp4 (4,632,458 bytes)\n",
      "\n",
      "================================================================================\n",
      "Uploading all videos to S3...\n",
      "================================================================================\n",
      "\n",
      "  Uploading Andy-Jassy-on-Amazon-Nova.mp4 (43,646,472 bytes)...\n",
      "✓ Successfully uploaded Andy-Jassy-on-Amazon-Nova.mp4 to S3\n",
      "  URI: s3://sagemaker-us-west-2-149536455198/video_understanding/Andy-Jassy-on-Amazon-Nova.mp4\n",
      "  Uploading Cheesecake.mp4 (11,080,848 bytes)...\n",
      "✓ Successfully uploaded Cheesecake.mp4 to S3\n",
      "  URI: s3://sagemaker-us-west-2-149536455198/video_understanding/Cheesecake.mp4\n",
      "  Uploading Meridian_Clip.mp4 (5,504,861 bytes)...\n",
      "✓ Successfully uploaded Meridian_Clip.mp4 to S3\n",
      "  URI: s3://sagemaker-us-west-2-149536455198/video_understanding/Meridian_Clip.mp4\n",
      "  Uploading the-sea.mp4 (4,632,458 bytes)...\n",
      "✓ Successfully uploaded the-sea.mp4 to S3\n",
      "  URI: s3://sagemaker-us-west-2-149536455198/video_understanding/the-sea.mp4\n",
      "\n",
      "================================================================================\n",
      "UPLOAD SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✓ Successfully uploaded: 4 video(s)\n",
      "  - Andy-Jassy-on-Amazon-Nova.mp4\n",
      "    URI: s3://sagemaker-us-west-2-149536455198/video_understanding/Andy-Jassy-on-Amazon-Nova.mp4\n",
      "  - Cheesecake.mp4\n",
      "    URI: s3://sagemaker-us-west-2-149536455198/video_understanding/Cheesecake.mp4\n",
      "  - Meridian_Clip.mp4\n",
      "    URI: s3://sagemaker-us-west-2-149536455198/video_understanding/Meridian_Clip.mp4\n",
      "  - the-sea.mp4\n",
      "    URI: s3://sagemaker-us-west-2-149536455198/video_understanding/the-sea.mp4\n",
      "\n",
      "================================================================================\n",
      "\n",
      "✓ Ready to proceed with 4 video(s)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Discover all MP4 files in the media directory\n",
    "print(\"Discovering videos in media directory...\\n\")\n",
    "video_files = sorted(glob.glob(\"media/*.mp4\"))\n",
    "\n",
    "print(f\"Found {len(video_files)} video file(s):\")\n",
    "for video_file in video_files:\n",
    "    filename = os.path.basename(video_file)\n",
    "    file_size = os.path.getsize(video_file)\n",
    "    print(f\"  - {filename} ({file_size:,} bytes)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Uploading all videos to S3...\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Dictionary to store video URIs (filename -> S3 URI)\n",
    "video_uris = {}\n",
    "upload_errors = []\n",
    "\n",
    "# Upload each video to S3\n",
    "for video_path in video_files:\n",
    "    filename = os.path.basename(video_path)\n",
    "    s3_key = f\"{VIDEO_SUBFOLDER}{filename}\"\n",
    "    \n",
    "    try:\n",
    "        # Upload video and store URI\n",
    "        uri = upload_video_to_s3(\n",
    "            local_path=video_path,\n",
    "            bucket_name=BUCKET_NAME,\n",
    "            s3_key=s3_key,\n",
    "            s3_client=s3_client\n",
    "        )\n",
    "        video_uris[filename] = uri\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        error_msg = f\"File not found: {filename}\"\n",
    "        upload_errors.append(error_msg)\n",
    "        video_uris[filename] = None\n",
    "        print(f\"✗ {error_msg}\")\n",
    "        print(\"⚠ Continuing with remaining uploads...\\n\")\n",
    "        \n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        error_msg = f\"AWS error uploading {filename}: [{error_code}] {e.response['Error']['Message']}\"\n",
    "        upload_errors.append(error_msg)\n",
    "        video_uris[filename] = None\n",
    "        print(f\"✗ {error_msg}\")\n",
    "        print(\"⚠ Continuing with remaining uploads...\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Unexpected error uploading {filename}: {str(e)}\"\n",
    "        upload_errors.append(error_msg)\n",
    "        video_uris[filename] = None\n",
    "        print(f\"✗ {error_msg}\")\n",
    "        print(\"⚠ Continuing with remaining uploads...\\n\")\n",
    "\n",
    "# Report upload results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"UPLOAD SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "successful_uploads = [f for f, uri in video_uris.items() if uri is not None]\n",
    "failed_uploads = [f for f, uri in video_uris.items() if uri is None]\n",
    "\n",
    "print(f\"\\n✓ Successfully uploaded: {len(successful_uploads)} video(s)\")\n",
    "for filename in successful_uploads:\n",
    "    print(f\"  - {filename}\")\n",
    "    print(f\"    URI: {video_uris[filename]}\")\n",
    "\n",
    "if failed_uploads:\n",
    "    print(f\"\\n✗ Failed uploads: {len(failed_uploads)} video(s)\")\n",
    "    for filename in failed_uploads:\n",
    "        print(f\"  - {filename}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Check if we have at least one video to continue\n",
    "if not successful_uploads:\n",
    "    raise RuntimeError(\n",
    "        \"Failed to upload any videos. Cannot proceed with video analysis.\\n\"\n",
    "        \"Please check the error messages above and resolve the issues.\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"\\n✓ Ready to proceed with {len(successful_uploads)} video(s)\")\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e2aa2-2f12-4516-a511-9d63d183a903",
   "metadata": {},
   "source": [
    "## Capability 1: Video Summarization\n",
    "\n",
    "Let's demonstrate Nova Omni's ability to generate concise summaries of video content, identifying key moments and events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "custom-prompt-strategy-id",
   "metadata": {},
   "source": [
    "### Custom Prompt Strategy for Different Video Types\n",
    "\n",
    "To maximize the value of Nova Omni's video understanding capabilities, we employ **content-aware prompting** - tailoring our analysis prompts to match the unique characteristics of each video type. This approach ensures we extract the most relevant and impressive insights from each piece of content.\n",
    "\n",
    "#### Why Custom Prompts Matter\n",
    "\n",
    "Different video types have fundamentally different characteristics and purposes:\n",
    "- **Cinematic content** emphasizes visual storytelling, mood, and cinematography\n",
    "- **Nature footage** focuses on environmental elements, aesthetics, and natural beauty\n",
    "- **Executive presentations** highlight key messages, product announcements, and business value\n",
    "\n",
    "By customizing our prompts, we can:\n",
    "1. **Extract domain-specific insights** that generic prompts might miss\n",
    "2. **Demonstrate versatility** of Nova Omni across diverse content types\n",
    "3. **Provide more actionable results** tailored to each video's purpose\n",
    "4. **Showcase the model's adaptability** to different analysis contexts\n",
    "\n",
    "#### Our Custom Prompt Approach\n",
    "\n",
    "For each video, we'll create prompts that:\n",
    "- **Meridian_Clip.mp4** (Cinematic): Focus on visual storytelling, dramatic moments, cinematographic techniques, and narrative arc\n",
    "- **the-sea.mp4** (Nature): Emphasize natural elements, environmental transitions, aesthetic qualities, and visual composition\n",
    "- **Andy-Jassy-on-Amazon-Nova.mp4** (Executive Presentation): Extract key announcements, strategic messages, business value propositions, and presenter communication style\n",
    "\n",
    "Let's see this strategy in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dfed9903-d5db-4a93-be93-d691644dbf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Video 1: Meridian_Clip.mp4\\n\n",
      "== Text Output ==\n",
      "- **Narrative Arc & Progression**: The video follows a man in a suit driving a vintage car through a desolate, mountainous landscape, transitioning from a sunny day to a rainy night, suggesting a journey marked by emotional or psychological turmoil.  \n",
      "- **Key Visual Moments**: The opening aerial shot of the car on a winding road sets a solitary tone, while the man’s focused expression and the rearview mirror revealing a woman’s face in the rain heighten tension and mystery.  \n",
      "- **Cinematographic Techniques**: The use of wide aerial shots contrasts with tight interior framing, emphasizing isolation. Dim lighting and rain-streaked windows create a moody, introspective atmosphere.  \n",
      "- **Mood & Atmosphere**: The barren landscape and shifting weather—from clear to stormy—mirror the protagonist’s inner state, evoking loneliness and impending conflict.  \n",
      "- **Character Actions**: The man’s steady grip on the steering wheel and occasional glances in the mirror suggest vigilance and emotional conflict, while the woman’s presence hints at a deeper, unresolved relationship.\n",
      "\n",
      "================================================================================\n",
      "RESPONSE CONTENT\n",
      "================================================================================\n",
      "- **Narrative Arc & Progression**: The video follows a man in a suit driving a vintage car through a desolate, mountainous landscape, transitioning from a sunny day to a rainy night, suggesting a journey marked by emotional or psychological turmoil.  \n",
      "- **Key Visual Moments**: The opening aerial shot of the car on a winding road sets a solitary tone, while the man’s focused expression and the rearview mirror revealing a woman’s face in the rain heighten tension and mystery.  \n",
      "- **Cinematographic Techniques**: The use of wide aerial shots contrasts with tight interior framing, emphasizing isolation. Dim lighting and rain-streaked windows create a moody, introspective atmosphere.  \n",
      "- **Mood & Atmosphere**: The barren landscape and shifting weather—from clear to stormy—mirror the protagonist’s inner state, evoking loneliness and impending conflict.  \n",
      "- **Character Actions**: The man’s steady grip on the steering wheel and occasional glances in the mirror suggest vigilance and emotional conflict, while the woman’s presence hints at a deeper, unresolved relationship.\n"
     ]
    }
   ],
   "source": [
    "# Custom prompt for cinematic content - emphasizes visual storytelling\n",
    "prompt_meridian = \"\"\"Analyze this cinematic video with a focus on visual storytelling and cinematography.\n",
    "\n",
    "Please provide a summary that captures:\n",
    "- The narrative arc and dramatic progression\n",
    "- Key visual moments and their emotional impact\n",
    "- Cinematographic techniques (camera work, lighting, composition)\n",
    "- Mood and atmosphere created through visuals\n",
    "- Character actions and their significance to the story\n",
    "\n",
    "Limit your summary to 5 main points in bullet format, emphasizing the cinematic qualities.\"\"\"\n",
    "\n",
    "prompt = prompt_meridian\n",
    "\n",
    "print(\"Analyzing Video 1: Meridian_Clip.mp4\\\\n\")\n",
    "\n",
    "# Get video URI from the video_uris dictionary - use just the filename!\n",
    "video1_filename = \"Meridian_Clip.mp4\"\n",
    "video1_uri = video_uris.get(video1_filename)\n",
    "\n",
    "# Check if video1 was uploaded successfully\n",
    "if video1_uri is None:\n",
    "    print(\"⚠ Skipping Video 1 analysis - video was not uploaded successfully.\\\\n\")\n",
    "    response1, content1 = None, None\n",
    "else:\n",
    "    try:\n",
    "        # Invoke model for first video - pass the S3 URI directly!\n",
    "        response1, content1 = invoke_nova_video(\n",
    "            video_uri=video1_uri,\n",
    "            prompt=prompt,\n",
    "            bedrock_client=bedrock_client\n",
    "        )\n",
    "\n",
    "        # Display response\n",
    "        display_response(content1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error analyzing Video 1: {str(e)}\")\n",
    "        print(\"⚠ Continuing with remaining analyses...\\\\n\")\n",
    "        response1, content1 = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0aaa0e6d-698e-4acf-948d-5fd0ff6279d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Video 2: the-sea.mp4\n",
      "== Text Output ==\n",
      "- The video showcases a rugged coastline with rocky cliffs and the ocean, highlighting the interplay between land and sea.  \n",
      "- It transitions from a wide aerial view of the rocky shoreline to a close-up of a seashell on a sunlit beach at sunset.  \n",
      "- The composition emphasizes natural beauty through the contrast of dark, textured rocks against the deep blue-green ocean and the warm golden hues of the sunset.  \n",
      "- The color palette features deep ocean blues, earthy tones in the cliffs, and warm golden light reflecting off the sand and seashell.  \n",
      "- The overall mood is serene and tranquil, evoking a sense of peace and connection with the natural environment.\n",
      "\n",
      "================================================================================\n",
      "RESPONSE CONTENT\n",
      "================================================================================\n",
      "- The video showcases a rugged coastline with rocky cliffs and the ocean, highlighting the interplay between land and sea.  \n",
      "- It transitions from a wide aerial view of the rocky shoreline to a close-up of a seashell on a sunlit beach at sunset.  \n",
      "- The composition emphasizes natural beauty through the contrast of dark, textured rocks against the deep blue-green ocean and the warm golden hues of the sunset.  \n",
      "- The color palette features deep ocean blues, earthy tones in the cliffs, and warm golden light reflecting off the sand and seashell.  \n",
      "- The overall mood is serene and tranquil, evoking a sense of peace and connection with the natural environment.\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing Video 2: the-sea.mp4\")\n",
    "\n",
    "# Get video URI from the video_uris dictionary\n",
    "video2_filename = \"the-sea.mp4\"\n",
    "video2_uri = video_uris.get(video2_filename)\n",
    "\n",
    "# Custom prompt for nature content - emphasizes natural elements and aesthetics\n",
    "prompt_sea = \"\"\"Analyze this nature video with a focus on environmental elements and visual aesthetics.\n",
    "\n",
    "Please provide a summary that captures:\n",
    "- Natural elements and scenery depicted (ocean, coastline, wildlife, etc.)\n",
    "- Visual transitions and environmental changes throughout the video\n",
    "- Aesthetic qualities and compositional beauty\n",
    "- Color palette and lighting in the natural setting\n",
    "- Overall mood and atmosphere of the natural environment. \n",
    "\n",
    "Limit your summary to 5 main points in bullet format, emphasizing the natural beauty and environmental aspects.\"\"\"\n",
    "prompt = prompt_sea\n",
    "\n",
    "# Check if video2 was uploaded successfully\n",
    "if video2_uri is None:\n",
    "    print(\"⚠ Skipping Video 2 analysis - video was not uploaded successfully.\\n\")\n",
    "    response2, content2 = None, None\n",
    "else:\n",
    "    try:\n",
    "        # Invoke model for second video\n",
    "        response2, content2= invoke_nova_video(\n",
    "            video_uri=video2_uri,\n",
    "            prompt=prompt,\n",
    "            bedrock_client=bedrock_client\n",
    "        )\n",
    "        \n",
    "        # Display response\n",
    "        display_response(content2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error analyzing Video 2: {str(e)}\")\n",
    "        print(\"⚠ Continuing with remaining analyses...\\n\")\n",
    "        response2, content2 = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "andy-jassy-summary-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Video 3: Andy-Jassy-on-Amazon-Nova.mp4\n",
      "\n",
      "== Text Output ==\n",
      "### Summary of Executive Presentation at AWS re:Invent  \n",
      "\n",
      "#### **1. Main Product Announcements & Strategic Initiatives**  \n",
      "- **New AI/ML Services**: Introduced advanced machine learning tools for real-time data analysis and predictive modeling, enabling businesses to derive actionable insights faster.  \n",
      "- **Enhanced Cloud Infrastructure**: Launched scalable compute and storage solutions optimized for high-performance workloads, supporting enterprise-grade applications.  \n",
      "- **Security Enhancements**: Expanded security offerings, including automated threat detection and compliance automation, to protect data across hybrid environments.  \n",
      "\n",
      "#### **2. Key Business Value Propositions & Benefits**  \n",
      "- **Cost Efficiency**: Demonstrated how AWS services reduce operational costs by up to 40% through automated resource management and pay-as-you-go pricing.  \n",
      "- **Agility & Scalability**: Highlighted the ability to rapidly deploy applications and scale infrastructure to meet fluctuating demand, ensuring uninterrupted business continuity.  \n",
      "- **Innovation Acceleration**: Emphasized how AWS tools empower developers to build AI-driven applications in days rather than months, fostering faster time-to-market.  \n",
      "\n",
      "#### **3. Presenter’s Communication Style & Emphasis Points**  \n",
      "- **Engaging & Conversational**: The presenter used relatable analogies (e.g., comparing cloud scalability to a “digital highway”) to simplify technical concepts.  \n",
      "- **Data-Driven Emphasis**: Repeatedly referenced customer success stories and performance metrics to validate claims, reinforcing trust and credibility.  \n",
      "- **Call to Action**: Urged attendees to leverage AWS resources for immediate innovation, framing the event as a catalyst for business transformation.  \n",
      "\n",
      "#### **4. Visual Aids, Demonstrations & Examples**  \n",
      "- **Live Demos**: Showcased real-time data processing workflows using AWS AI/ML services, illustrating how businesses can automate decision-making.  \n",
      "- **Infographics**: Presented charts comparing AWS performance metrics against competitors, emphasizing superior speed and reliability.  \n",
      "- **Customer Testimonials**: Included video clips from enterprise clients discussing reduced downtime and accelerated product launches.  \n",
      "\n",
      "#### **5. Target Audience & Intended Business Impact**  \n",
      "- **Target Audience**: Developers, IT leaders, and business decision-makers seeking to modernize infrastructure and adopt AI-driven solutions.  \n",
      "- **Intended Impact**: Drive operational efficiency, enhance security, and unlock innovation potential, positioning AWS as the preferred platform for future-ready enterprises.\n",
      "\n",
      "================================================================================\n",
      "RESPONSE CONTENT\n",
      "================================================================================\n",
      "### Summary of Executive Presentation at AWS re:Invent  \n",
      "\n",
      "#### **1. Main Product Announcements & Strategic Initiatives**  \n",
      "- **New AI/ML Services**: Introduced advanced machine learning tools for real-time data analysis and predictive modeling, enabling businesses to derive actionable insights faster.  \n",
      "- **Enhanced Cloud Infrastructure**: Launched scalable compute and storage solutions optimized for high-performance workloads, supporting enterprise-grade applications.  \n",
      "- **Security Enhancements**: Expanded security offerings, including automated threat detection and compliance automation, to protect data across hybrid environments.  \n",
      "\n",
      "#### **2. Key Business Value Propositions & Benefits**  \n",
      "- **Cost Efficiency**: Demonstrated how AWS services reduce operational costs by up to 40% through automated resource management and pay-as-you-go pricing.  \n",
      "- **Agility & Scalability**: Highlighted the ability to rapidly deploy applications and scale infrastructure to meet fluctuating demand, ensuring uninterrupted business continuity.  \n",
      "- **Innovation Acceleration**: Emphasized how AWS tools empower developers to build AI-driven applications in days rather than months, fostering faster time-to-market.  \n",
      "\n",
      "#### **3. Presenter’s Communication Style & Emphasis Points**  \n",
      "- **Engaging & Conversational**: The presenter used relatable analogies (e.g., comparing cloud scalability to a “digital highway”) to simplify technical concepts.  \n",
      "- **Data-Driven Emphasis**: Repeatedly referenced customer success stories and performance metrics to validate claims, reinforcing trust and credibility.  \n",
      "- **Call to Action**: Urged attendees to leverage AWS resources for immediate innovation, framing the event as a catalyst for business transformation.  \n",
      "\n",
      "#### **4. Visual Aids, Demonstrations & Examples**  \n",
      "- **Live Demos**: Showcased real-time data processing workflows using AWS AI/ML services, illustrating how businesses can automate decision-making.  \n",
      "- **Infographics**: Presented charts comparing AWS performance metrics against competitors, emphasizing superior speed and reliability.  \n",
      "- **Customer Testimonials**: Included video clips from enterprise clients discussing reduced downtime and accelerated product launches.  \n",
      "\n",
      "#### **5. Target Audience & Intended Business Impact**  \n",
      "- **Target Audience**: Developers, IT leaders, and business decision-makers seeking to modernize infrastructure and adopt AI-driven solutions.  \n",
      "- **Intended Impact**: Drive operational efficiency, enhance security, and unlock innovation potential, positioning AWS as the preferred platform for future-ready enterprises.\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing Video 3: Andy-Jassy-on-Amazon-Nova.mp4\\n\")\n",
    "\n",
    "# Custom prompt for executive presentation - emphasizes key announcements and business value\n",
    "prompt_andy = \"\"\" Analyze this executive presentation video with a focus on key messages and strategic announcements.\n",
    "\n",
    "Please provide a summary that captures:\n",
    "- Main product announcements or strategic initiatives discussed\n",
    "- Key business value propositions and benefits highlighted\n",
    "- Presenter's communication style and emphasis points\n",
    "- Visual aids, demonstrations, or examples shown\n",
    "- Target audience and intended business impact\n",
    "\n",
    "Limit your summary to 5 main points in bullet format, emphasizing the executive messaging and business value.\n",
    "\"\"\"\n",
    "prompt = prompt_andy\n",
    "\n",
    "# Get video URI from the video_uris dictionary\n",
    "video3_filename = \"Andy-Jassy-on-Amazon-Nova.mp4\"\n",
    "video3_uri = video_uris.get(video3_filename)\n",
    "\n",
    "# Check if video3 was uploaded successfully\n",
    "if video3_uri is None:\n",
    "    print(\"⚠ Skipping Video 3 analysis - video was not uploaded successfully.\\n\")\n",
    "    response3, content3 = None, None\n",
    "else:\n",
    "    try:\n",
    "        # Invoke model for third video\n",
    "        response3, content3 = invoke_nova_video(\n",
    "            video_uri=video3_uri,\n",
    "            prompt=prompt,\n",
    "            bedrock_client=bedrock_client\n",
    "        )\n",
    "        \n",
    "        # Display response\n",
    "        display_response(content3)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error analyzing Video 3: {str(e)}\")\n",
    "        print(\"⚠ Continuing with remaining analyses...\\n\")\n",
    "        response3, content3 = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2-a3b4-5678-2345-789012345678",
   "metadata": {},
   "source": [
    "## Capability 2: Structured Action Timeline\n",
    "\n",
    "Beyond simple event detection, Nova Omni can generate structured, machine-readable timelines of all actions occurring in a video. This capability is particularly valuable for programmatic processing, enabling automated video indexing, content analysis pipelines, and integration with other systems.\n",
    "\n",
    "### Use Cases for Structured Action Timelines:\n",
    "\n",
    "- **Video Indexing**: Create searchable databases of video content\n",
    "- **Content Management Systems**: Automatically tag and categorize video segments\n",
    "- **Automated Editing**: Identify and extract specific action sequences\n",
    "- **Training Data Generation**: Create labeled datasets for machine learning\n",
    "- **Compliance & Auditing**: Document all activities in surveillance or training videos\n",
    "- **Sports Analytics**: Track player movements and game events systematically\n",
    "- **Accessibility**: Generate detailed video descriptions for visually impaired users\n",
    "\n",
    "The structured JSON format makes it easy to:\n",
    "- Parse and process results programmatically\n",
    "- Store action data in databases\n",
    "- Generate reports and visualizations\n",
    "- Integrate with downstream applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3-b4c5-6789-3456-890123456789",
   "metadata": {},
   "source": [
    "### Generating Action Timeline for Cheesecake.mp4\n",
    "\n",
    "Let's analyze the Cheesecake clip and generate a chronological timeline of all actions and activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e1f2a3b4-c5d6-7890-4567-901234567890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Video 4: Cheesecake.mp4\\n\n",
      "Generating Structured Action Timeline\n",
      "\n",
      "Video: Cheesecake.mp4\n",
      "\n",
      "== Text Output ==\n",
      "{\n",
      "  \"recipe_name\": \"5-Minute Cheesecake\",\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"step_number\": 1,\n",
      "      \"action\": \"Melt 1 tablespoon of butter in a small bowl using a microwave or stovetop\",\n",
      "      \"timestamp\": \"00:00-00:04\",\n",
      "      \"ingredients\": [\"butter\"],\n",
      "      \"technique\": \"melting\",\n",
      "      \"equipment\": [\"microwave\", \"small bowl\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 2,\n",
      "      \"action\": \"Crush 2 graham crackers into crumbs and mix with melted butter\",\n",
      "      \"timestamp\": \"00:06-00:14\",\n",
      "      \"ingredients\": [\"graham crackers\", \"butter\"],\n",
      "      \"technique\": \"crushing and mixing\",\n",
      "      \"equipment\": [\"bowl\", \"spoon\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 3,\n",
      "      \"action\": \"Combine 4 ounces cream cheese, 2 spoonfuls sugar, and vanilla in a bowl\",\n",
      "      \"timestamp\": \"00:16-00:20\",\n",
      "      \"ingredients\": [\"cream cheese\", \"sugar\", \"vanilla\"],\n",
      "      \"technique\": \"mixing\",\n",
      "      \"equipment\": [\"bowl\", \"spoon\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 4,\n",
      "      \"action\": \"Blend ingredients until smooth\",\n",
      "      \"timestamp\": \"00:21-00:25\",\n",
      "      \"ingredients\": [],\n",
      "      \"technique\": \"blending\",\n",
      "      \"equipment\": [\"spoon\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 5,\n",
      "      \"action\": \"Microwave mixture at 50% power for 4 minutes in 45-second intervals\",\n",
      "      \"timestamp\": \"00:26-00:31\",\n",
      "      \"ingredients\": [],\n",
      "      \"technique\": \"microwave cooking\",\n",
      "      \"equipment\": [\"microwave\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 6,\n",
      "      \"action\": \"Chill mixture in freezer until firm\",\n",
      "      \"timestamp\": \"00:32-00:33\",\n",
      "      \"ingredients\": [],\n",
      "      \"technique\": \"chilling\",\n",
      "      \"equipment\": [\"freezer\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 7,\n",
      "      \"action\": \"Scrape mixture into serving bowl and garnish with raspberries\",\n",
      "      \"timestamp\": \"00:34-00:47\",\n",
      "      \"ingredients\": [\"raspberries\"],\n",
      "      \"technique\": \"serving and garnishing\",\n",
      "      \"equipment\": [\"serving bowl\", \"spoon\"]\n",
      "    }\n",
      "  ],\n",
      "  \"key_tips\": [\n",
      "    \"Use 50% microwave power for even cooking\",\n",
      "    \"Chill thoroughly for best texture\",\n",
      "    \"Garnish with fresh berries for presentation\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "RAW JSON RESPONSE\n",
      "================================================================================\n",
      "{\n",
      "  \"recipe_name\": \"5-Minute Cheesecake\",\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"step_number\": 1,\n",
      "      \"action\": \"Melt 1 tablespoon of butter in a small bowl using a microwave or stovetop\",\n",
      "      \"timestamp\": \"00:00-00:04\",\n",
      "      \"ingredients\": [\"butter\"],\n",
      "      \"technique\": \"melting\",\n",
      "      \"equipment\": [\"microwave\", \"small bowl\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 2,\n",
      "      \"action\": \"Crush 2 graham crackers into crumbs and mix with melted butter\",\n",
      "      \"timestamp\": \"00:06-00:14\",\n",
      "      \"ingredients\": [\"graham crackers\", \"butter\"],\n",
      "      \"technique\": \"crushing and mixing\",\n",
      "      \"equipment\": [\"bowl\", \"spoon\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 3,\n",
      "      \"action\": \"Combine 4 ounces cream cheese, 2 spoonfuls sugar, and vanilla in a bowl\",\n",
      "      \"timestamp\": \"00:16-00:20\",\n",
      "      \"ingredients\": [\"cream cheese\", \"sugar\", \"vanilla\"],\n",
      "      \"technique\": \"mixing\",\n",
      "      \"equipment\": [\"bowl\", \"spoon\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 4,\n",
      "      \"action\": \"Blend ingredients until smooth\",\n",
      "      \"timestamp\": \"00:21-00:25\",\n",
      "      \"ingredients\": [],\n",
      "      \"technique\": \"blending\",\n",
      "      \"equipment\": [\"spoon\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 5,\n",
      "      \"action\": \"Microwave mixture at 50% power for 4 minutes in 45-second intervals\",\n",
      "      \"timestamp\": \"00:26-00:31\",\n",
      "      \"ingredients\": [],\n",
      "      \"technique\": \"microwave cooking\",\n",
      "      \"equipment\": [\"microwave\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 6,\n",
      "      \"action\": \"Chill mixture in freezer until firm\",\n",
      "      \"timestamp\": \"00:32-00:33\",\n",
      "      \"ingredients\": [],\n",
      "      \"technique\": \"chilling\",\n",
      "      \"equipment\": [\"freezer\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 7,\n",
      "      \"action\": \"Scrape mixture into serving bowl and garnish with raspberries\",\n",
      "      \"timestamp\": \"00:34-00:47\",\n",
      "      \"ingredients\": [\"raspberries\"],\n",
      "      \"technique\": \"serving and garnishing\",\n",
      "      \"equipment\": [\"serving bowl\", \"spoon\"]\n",
      "    }\n",
      "  ],\n",
      "  \"key_tips\": [\n",
      "    \"Use 50% microwave power for even cooking\",\n",
      "    \"Chill thoroughly for best texture\",\n",
      "    \"Garnish with fresh berries for presentation\"\n",
      "  ]\n",
      "}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing Video 4: Cheesecake.mp4\\\\n\")\n",
    "\n",
    "# Get video URI from the video_uris dictionary - use just the filename!\n",
    "video4_filename = \"Cheesecake.mp4\"\n",
    "video4_uri = video_uris.get(video4_filename)\n",
    "\n",
    "print(\"Generating Structured Action Timeline\\n\")\n",
    "print(\"Video: Cheesecake.mp4\\n\")\n",
    "\n",
    "# Define JSON schema for action timeline in prompt\n",
    "action_timeline_prompt = \"\"\" Analyze this cooking video and create a detailed timeline of all culinary actions, steps, and techniques shown.\n",
    "\n",
    "Follow these guidelines:\n",
    "1. Identify each cooking step with its corresponding timestamp\n",
    "2. Describe ingredients being added or prepared\n",
    "3. Note cooking techniques and methods used (mixing, baking, chilling, etc.)\n",
    "4. Capture equipment or tools being used\n",
    "5. Include temperature settings or timing instructions if visible\n",
    "6. Note any visual cues (texture changes, color changes, consistency)\n",
    "7. Output timestamp in MM:SS format\n",
    "8. Focus on actionable recipe steps that someone could follow\n",
    "\n",
    "Output in the following JSON schema:\n",
    "{\n",
    "  \"recipe_name\": \"name of the dish being prepared\",\n",
    "  \"actions\": [\n",
    "    {\n",
    "      \"step_number\": 1,\n",
    "      \"action\": \"detailed description of the cooking step\",\n",
    "      \"timestamp\": \"MM:SS\",\n",
    "      \"ingredients\": [\"list of ingredients used in this step\"],\n",
    "      \"technique\": \"cooking technique or method used\",\n",
    "      \"equipment\": [\"tools or equipment used\"]\n",
    "    }\n",
    "  ],\n",
    "  \"key_tips\": [\"any important tips or techniques highlighted in the video\"]\n",
    "}\n",
    "\n",
    "Provide ONLY the JSON output, no additional text. \"\"\"\n",
    "\n",
    "# Invoke model with structured output request\n",
    "response_timeline, content_timeline = invoke_nova_video(\n",
    "    video_uri=video4_uri,\n",
    "    prompt=action_timeline_prompt,\n",
    "    bedrock_client=bedrock_client\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RAW JSON RESPONSE\")\n",
    "print(\"=\"*80)\n",
    "print(content_timeline)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7-f8a9-0123-7890-234567890123",
   "metadata": {},
   "source": [
    "### Generating Action Timeline for Cheesecake.mp4\n",
    "\n",
    "Let's also generate an action timeline for the Cheesecake.mp4 video to demonstrate the capability across different content types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5d6e7f8-a9b0-1234-8901-345678901234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Structured Action Timeline\n",
      "\n",
      "Video: Cheesecake.mp4\n",
      "\n",
      "== Text Output ==\n",
      "{\n",
      "  \"recipe_name\": \"5-Minute Cheesecake\",\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"step_number\": 1,\n",
      "      \"action\": \"Place 1 tablespoon of butter into a small white bowl and melt it in the microwave\",\n",
      "      \"timestamp\": \"00:00-00:03\",\n",
      "      \"ingredients\": [\"butter\"],\n",
      "      \"technique\": \"melting\",\n",
      "      \"equipment\": [\"microwave\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 2,\n",
      "      \"action\": \"Crush graham crackers into crumbs and mix with melted butter\",\n",
      "      \"timestamp\": \"00:06-00:15\",\n",
      "      \"ingredients\": [\"graham crackers\"],\n",
      "      \"technique\": \"crushing and mixing\",\n",
      "      \"equipment\": [\"spoon\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 3,\n",
      "      \"action\": \"Add 4 ounces of cream cheese, 2 spoonfuls of sugar, and vanilla to a bowl\",\n",
      "      \"timestamp\": \"00:16-00:20\",\n",
      "      \"ingredients\": [\"cream cheese\", \"sugar\", \"vanilla\"],\n",
      "      \"technique\": \"combining ingredients\",\n",
      "      \"equipment\": [\"spoon\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 4,\n",
      "      \"action\": \"Mix ingredients until smooth and creamy\",\n",
      "      \"timestamp\": \"00:21-00:25\",\n",
      "      \"ingredients\": [],\n",
      "      \"technique\": \"whisking\",\n",
      "      \"equipment\": [\"spoon\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 5,\n",
      "      \"action\": \"Microwave mixture at 50% power for 4 minutes in 45-second intervals\",\n",
      "      \"timestamp\": \"00:26-00:30\",\n",
      "      \"ingredients\": [],\n",
      "      \"technique\": \"microwave cooking\",\n",
      "      \"equipment\": [\"microwave\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 6,\n",
      "      \"action\": \"Chill mixture in freezer until firm\",\n",
      "      \"timestamp\": \"00:32-00:33\",\n",
      "      \"ingredients\": [],\n",
      "      \"technique\": \"chilling\",\n",
      "      \"equipment\": [\"freezer\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 7,\n",
      "      \"action\": \"Spread melted graham cracker mixture over chilled cheesecake base\",\n",
      "      \"timestamp\": \"00:34-00:40\",\n",
      "      \"ingredients\": [\"graham cracker crumbs\"],\n",
      "      \"technique\": \"spreading\",\n",
      "      \"equipment\": [\"spoon\"]\n",
      "    },\n",
      "    {\n",
      "      \"step_number\": 8,\n",
      "      \"action\": \"Garnish with raspberries before serving\",\n",
      "      \"timestamp\": \"00:44-00:46\",\n",
      "      \"ingredients\": [\"raspberries\"],\n",
      "      \"technique\": \"garnishing\",\n",
      "      \"equipment\": [\"spoon\"]\n",
      "    }\n",
      "  ],\n",
      "  \"key_tips\": [\n",
      "    \"Use 50% microwave power for even cooking\",\n",
      "    \"Chill thoroughly before adding graham cracker layer\",\n",
      "    \"Serve with fresh berries for added flavor\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "STRUCTURED ACTION TIMELINE\n",
      "================================================================================\n",
      "\n",
      "Video: Cheesecake.mp4\n",
      "Total Actions Detected: 8\n",
      "\n",
      " 1. [00:00-00:03] Place 1 tablespoon of butter into a small white bowl and melt it in the microwave\n",
      " 2. [00:06-00:15] Crush graham crackers into crumbs and mix with melted butter\n",
      " 3. [00:16-00:20] Add 4 ounces of cream cheese, 2 spoonfuls of sugar, and vanilla to a bowl\n",
      " 4. [00:21-00:25] Mix ingredients until smooth and creamy\n",
      " 5. [00:26-00:30] Microwave mixture at 50% power for 4 minutes in 45-second intervals\n",
      " 6. [00:32-00:33] Chill mixture in freezer until firm\n",
      " 7. [00:34-00:40] Spread melted graham cracker mixture over chilled cheesecake base\n",
      " 8. [00:44-00:46] Garnish with raspberries before serving\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating Structured Action Timeline\\n\")\n",
    "print(\"Video: Cheesecake.mp4\\n\")\n",
    "\n",
    "# Invoke model for second video\n",
    "response_timeline4, content_timeline4 = invoke_nova_video(\n",
    "    video_uri=video4_uri,\n",
    "    prompt=action_timeline_prompt,\n",
    "    bedrock_client=bedrock_client\n",
    ")\n",
    "\n",
    "# Parse and display\n",
    "try:\n",
    "    action_data4 = parse_json_response(content_timeline4)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STRUCTURED ACTION TIMELINE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nVideo: Cheesecake.mp4\")\n",
    "    print(f\"Total Actions Detected: {len(action_data4.get('actions', []))}\\n\")\n",
    "    \n",
    "    for idx, action_entry in enumerate(action_data4.get('actions', []), 1):\n",
    "        timestamp = action_entry.get('timestamp', 'N/A')\n",
    "        action = action_entry.get('action', 'No description')\n",
    "        print(f\"{idx:2d}. [{timestamp}] {action}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Error parsing JSON response: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9-b0c1-2345-9012-456789012345",
   "metadata": {},
   "source": [
    "### Structured Action Timeline Summary\n",
    "\n",
    "We've successfully demonstrated Nova Omni's ability to generate structured, JSON-formatted action timelines. This capability provides:\n",
    "\n",
    "**Key Benefits:**\n",
    "- **Machine-Readable Format**: JSON output can be easily parsed and processed by applications\n",
    "- **Chronological Organization**: Actions are listed in temporal order with precise timestamps\n",
    "- **Programmatic Integration**: Results can be stored in databases, used in APIs, or fed into analytics pipelines\n",
    "- **Scalability**: Automated processing enables analysis of large video libraries\n",
    "\n",
    "**Practical Applications:**\n",
    "- Building searchable video databases\n",
    "- Automating content moderation workflows\n",
    "- Generating training datasets for ML models\n",
    "- Creating detailed video documentation\n",
    "- Enabling advanced video analytics\n",
    "\n",
    "The structured format makes it straightforward to integrate video understanding into larger systems and workflows, opening up possibilities for automated video processing at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1-d2e3-4567-1234-678901234567",
   "metadata": {},
   "source": [
    "## Capability 3: Content Moderation\n",
    "\n",
    "Content moderation is a critical capability for platforms that host user-generated content, media companies, and organizations that need to ensure their video content meets safety and compliance standards. Nova Omni can analyze both visual and audio content to detect potentially inappropriate material.\n",
    "\n",
    "### Use Cases for Content Moderation:\n",
    "\n",
    "- **Social Media Platforms**: Automatically flag inappropriate user-uploaded videos\n",
    "- **E-Learning Platforms**: Ensure educational content is appropriate for target age groups\n",
    "- **Corporate Training**: Verify training videos meet workplace standards\n",
    "- **Broadcasting**: Pre-screen content before airing\n",
    "- **User-Generated Content**: Moderate submissions before publication\n",
    "- **Compliance & Legal**: Document content for regulatory requirements\n",
    "- **Brand Safety**: Ensure advertising appears alongside appropriate content\n",
    "\n",
    "### What We'll Detect:\n",
    "\n",
    "1. **Explicit Visual Content**: Nudity, violence, graphic imagery, or other adult material\n",
    "2. **Toxic Audio Content**: Profanity, hate speech, threats, or harmful language\n",
    "\n",
    "For each detected issue, we'll receive:\n",
    "- Type of content detected\n",
    "- Severity level (low/medium/high)\n",
    "- Precise timestamp in MM:SS format\n",
    "- Detailed description of the finding\n",
    "\n",
    "Let's analyze our test videos for content moderation purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c1d2-e3f4-5678-2345-789012345678",
   "metadata": {},
   "source": [
    "### Visual Content Analysis\n",
    "\n",
    "First, let's analyze the video for explicit visual content including nudity, violence, or other adult material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0c1d2e3-f4a5-6789-3456-890123456789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Visual Content for Moderation\n",
      "\n",
      "Video: Meridian_Clip.mp4\n",
      "\n",
      "== Text Output ==\n",
      "The video does not contain any explicit visual content that would require content warnings. There is no nudity, violence, or graphic imagery present. The scenes focus on a man driving a vintage car through a mountainous landscape, with no disturbing or shocking visual elements. The content appears to be safe for general audiences from a visual perspective.\n",
      "\n",
      "================================================================================\n",
      "RESPONSE CONTENT\n",
      "================================================================================\n",
      "The video does not contain any explicit visual content that would require content warnings. There is no nudity, violence, or graphic imagery present. The scenes focus on a man driving a vintage car through a mountainous landscape, with no disturbing or shocking visual elements. The content appears to be safe for general audiences from a visual perspective.\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing Visual Content for Moderation\\n\")\n",
    "print(\"Video: Meridian_Clip.mp4\\n\")\n",
    "\n",
    "# Create prompt for explicit visual content detection\n",
    "visual_moderation_prompt = \"\"\"\n",
    "Analyze this video for explicit visual content that may be inappropriate or require content warnings.\n",
    "\n",
    "Examine the video for:\n",
    "- Nudity or sexually explicit content\n",
    "- Violence or graphic imagery\n",
    "- Disturbing or shocking visual content\n",
    "- Other adult material that may require age restrictions\n",
    "\n",
    "For any detected content, provide:\n",
    "1. Type of content detected\n",
    "2. Severity level: low (mild), medium (moderate), or high (severe)\n",
    "3. Timestamp in MM:SS format when the content appears\n",
    "4. Brief description of what was detected\n",
    "\n",
    "If no explicit visual content is detected, clearly state that the video appears to be safe for general audiences from a visual content perspective.\n",
    "\n",
    "Be specific and factual in your assessment.\n",
    "\"\"\"\n",
    "\n",
    "# Invoke model for visual content analysis\n",
    "response_visual, content_visual = invoke_nova_video(\n",
    "    video_uri=video1_uri,\n",
    "    prompt=visual_moderation_prompt,\n",
    "    temperature=0.1,  # Lower temperature for more consistent moderation\n",
    "    bedrock_client=bedrock_client\n",
    ")\n",
    "\n",
    "# Display response\n",
    "display_response(content_visual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4-a5b6-7890-4567-901234567890",
   "metadata": {},
   "source": [
    "### Audio Content Analysis\n",
    "\n",
    "Now let's analyze the audio track for toxic content including profanity, hate speech, or harmful language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2e3f4a5-b6c7-8901-5678-012345678901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Audio Content for Moderation\n",
      "\n",
      "Video: Meridian_Clip.mp4\n",
      "\n",
      "== Text Output ==\n",
      "No toxic audio content was detected in this video.\n",
      "\n",
      "================================================================================\n",
      "RESPONSE CONTENT\n",
      "================================================================================\n",
      "No toxic audio content was detected in this video.\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing Audio Content for Moderation\\n\")\n",
    "print(\"Video: Meridian_Clip.mp4\\n\")\n",
    "\n",
    "# Create prompt for toxic audio content detection\n",
    "audio_moderation_prompt = \"\"\"\n",
    "Analyze the audio content in this video for toxic or inappropriate language.\n",
    "\n",
    "Listen for:\n",
    "- Profanity or vulgar language\n",
    "- Hate speech or discriminatory language\n",
    "- Threats or violent language\n",
    "- Harassment or bullying language\n",
    "- Other harmful or inappropriate speech\n",
    "\n",
    "For any detected content, provide:\n",
    "1. Type of toxic content detected\n",
    "2. Severity level: low (mild), medium (moderate), or high (severe)\n",
    "3. Timestamp in MM:SS format when the language occurs\n",
    "4. Context or description (without repeating explicit language verbatim)\n",
    "\n",
    "If no toxic audio content is detected, clearly state that the audio appears to be appropriate for general audiences.\n",
    "\n",
    "If there is no spoken audio or dialogue in the video, note that as well.\n",
    "\n",
    "Be specific and factual in your assessment.\n",
    "\"\"\"\n",
    "\n",
    "# Invoke model for audio content analysis\n",
    "response_audio, content_audio = invoke_nova_video(\n",
    "    video_uri=video1_uri,\n",
    "    prompt=audio_moderation_prompt,\n",
    "    temperature=0.1,  # Lower temperature for more consistent moderation\n",
    "    bedrock_client=bedrock_client\n",
    ")\n",
    "\n",
    "# Display response\n",
    "display_response(content_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4a5b6-c7d8-9012-6789-123456789012",
   "metadata": {},
   "source": [
    "### Content Moderation Analysis for the-sea.mp4 Video\n",
    "\n",
    "Let's also analyze our second video (the-sea.mp4) to demonstrate the moderation capability across different content types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4a5b6c7-d8e9-0123-7890-234567890123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Visual Content for Moderation\n",
      "\n",
      "Video: the-sea.mp4\n",
      "\n",
      "== Text Output ==\n",
      "The video features a serene coastal landscape with rocky cliffs and the ocean, followed by a close-up of a seashell on a beach at sunset. There are no elements of nudity, violence, or other inappropriate content. The visuals are peaceful and natural, making the video suitable for general audiences.\n",
      "\n",
      "================================================================================\n",
      "RESPONSE CONTENT\n",
      "================================================================================\n",
      "The video features a serene coastal landscape with rocky cliffs and the ocean, followed by a close-up of a seashell on a beach at sunset. There are no elements of nudity, violence, or other inappropriate content. The visuals are peaceful and natural, making the video suitable for general audiences.\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing Visual Content for Moderation\\n\")\n",
    "print(\"Video: the-sea.mp4\\n\")\n",
    "\n",
    "# Invoke model for visual content analysis on second video\n",
    "response_visual2, content_visual2 = invoke_nova_video(\n",
    "    video_uri=video2_uri,\n",
    "    prompt=visual_moderation_prompt,\n",
    "    temperature=0.1,\n",
    "    bedrock_client=bedrock_client\n",
    ")\n",
    "\n",
    "# Display response\n",
    "display_response(content_visual2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a5b6c7d8-e9f0-1234-8901-345678901234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Audio Content for Moderation\n",
      "\n",
      "Video: the-sea.mp4\n",
      "\n",
      "== Text Output ==\n",
      "The audio features a serene coastal scene with waves crashing against rocks and a distant view of the ocean. There is no speech or dialogue present in this clip. The predominant sounds are those of nature, creating a peaceful and calming atmosphere.\n",
      "\n",
      "================================================================================\n",
      "RESPONSE CONTENT\n",
      "================================================================================\n",
      "The audio features a serene coastal scene with waves crashing against rocks and a distant view of the ocean. There is no speech or dialogue present in this clip. The predominant sounds are those of nature, creating a peaceful and calming atmosphere.\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing Audio Content for Moderation\\n\")\n",
    "print(\"Video: the-sea.mp4\\n\")\n",
    "\n",
    "# Invoke model for audio content analysis on second video\n",
    "response_audio2, content_audio2 = invoke_nova_video(\n",
    "    video_uri=video2_uri,\n",
    "    prompt=audio_moderation_prompt,\n",
    "    temperature=0.1,\n",
    "    bedrock_client=bedrock_client\n",
    ")\n",
    "\n",
    "# Display response\n",
    "display_response(content_audio2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7d8e9-f0a1-2345-9012-456789012345",
   "metadata": {},
   "source": [
    "### Content Moderation Summary\n",
    "\n",
    "We've successfully demonstrated Nova Omni's content moderation capabilities for both visual and audio content across two different videos.\n",
    "\n",
    "**Key Capabilities Demonstrated:**\n",
    "\n",
    "1. **Visual Content Analysis**: Detection of explicit imagery, violence, and inappropriate visual content\n",
    "2. **Audio Content Analysis**: Detection of profanity, hate speech, and toxic language\n",
    "3. **Severity Assessment**: Classification of findings by severity level (low/medium/high)\n",
    "4. **Temporal Precision**: Exact timestamps for when inappropriate content appears\n",
    "5. **Detailed Reporting**: Comprehensive descriptions of detected issues\n",
    "\n",
    "**Practical Applications:**\n",
    "\n",
    "- **Automated Moderation**: Scale content review across large video libraries\n",
    "- **Pre-Publication Screening**: Flag content before it goes live\n",
    "- **Compliance Documentation**: Create audit trails for regulatory requirements\n",
    "- **Age-Appropriate Filtering**: Classify content for different audience segments\n",
    "- **Brand Safety**: Ensure advertising appears alongside appropriate content\n",
    "- **Human Review Prioritization**: Focus human moderators on flagged content\n",
    "\n",
    "**Important Considerations:**\n",
    "\n",
    "- Content moderation should be used as part of a comprehensive moderation strategy\n",
    "- AI-based moderation works best when combined with human review for edge cases\n",
    "- Different platforms and contexts may have different standards for what constitutes inappropriate content\n",
    "- Regular calibration and testing ensures moderation accuracy over time\n",
    "\n",
    "The combination of visual and audio analysis provides comprehensive coverage for content safety, helping organizations maintain appropriate standards while scaling their content operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8e9f0-a1b2-3456-1234-678901234567",
   "metadata": {},
   "source": [
    "## Capability 4: Logo Recognition\n",
    "\n",
    "Logo recognition is a powerful capability for brand monitoring, competitive analysis, and understanding product placement in video content. Nova Pro can identify brand logos and trademarks appearing in video frames, providing detailed information about when and how brands appear in your content.\n",
    "\n",
    "### Use Cases for Logo Recognition:\n",
    "\n",
    "- **Brand Monitoring**: Track your brand's visibility across video content\n",
    "- **Competitive Intelligence**: Identify competitor brands in market research videos\n",
    "- **Product Placement Analysis**: Measure brand exposure in entertainment content\n",
    "- **Sponsorship Verification**: Confirm sponsor logos appear as contracted\n",
    "- **Advertising Analytics**: Quantify brand visibility in commercial content\n",
    "- **Content Rights Management**: Identify unauthorized use of branded content\n",
    "- **Market Research**: Analyze brand presence in user-generated content\n",
    "- **Sports Analytics**: Track sponsor visibility during sporting events\n",
    "\n",
    "### What We'll Extract:\n",
    "\n",
    "For each detected logo, we'll receive:\n",
    "- **Logo/Brand Name**: The identified brand or trademark\n",
    "- **Timestamp**: When the logo first appears (MM:SS format)\n",
    "- **Duration**: How long the logo remains visible\n",
    "- **Visual Description**: Characteristics of the logo (colors, placement, size)\n",
    "\n",
    "The structured JSON format makes it easy to:\n",
    "- Generate brand visibility reports\n",
    "- Calculate total exposure time for each brand\n",
    "- Create searchable brand appearance databases\n",
    "- Integrate with analytics and reporting systems\n",
    "\n",
    "Let's analyze our test videos for logo recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9f0a1-b2c3-4567-2345-789012345678",
   "metadata": {},
   "source": [
    "### Logo Detection in Andy-Jassy-on-Amazon-Nova.mp4\n",
    "\n",
    "Let's analyze the Andy-Jassy-on-Amazon-Nova clip to identify any brand logos or trademarks that appear in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9f0a1b2-c3d4-5678-3456-890123456789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Video for Logo Recognition\n",
      "\n",
      "Video: Andy-Jassy-on-Amazon-Nova.mp4\n",
      "\n",
      "== Text Output ==\n",
      "```json\n",
      "{\n",
      "  \"presentation_context\": \"A speaker presents at AWS re:Invent, using hand gestures and addressing an engaged audience in a blue-lit conference hall.\",\n",
      "  \"primary_brand\": \"AWS\",\n",
      "  \"logos\": [\n",
      "    {\n",
      "      \"logo_name\": \"AWS\",\n",
      "      \"brand_category\": \"company logo\",\n",
      "      \"timestamp\": \"00:00\",\n",
      "      \"duration\": \"throughout presentation\",\n",
      "      \"placement\": \"bottom right corner of the screen\",\n",
      "      \"description\": \"Small white AWS logo in the lower-right corner of the frame, consistently visible throughout the presentation.\",\n",
      "      \"prominence\": \"background\",\n",
      "      \"context\": \"Brand watermark during the entire presentation\"\n",
      "    }\n",
      "  ],\n",
      "  \"brand_mentions\": []\n",
      "}\n",
      "```\n",
      "\n",
      "================================================================================\n",
      "RAW JSON RESPONSE\n",
      "================================================================================\n",
      "```json\n",
      "{\n",
      "  \"presentation_context\": \"A speaker presents at AWS re:Invent, using hand gestures and addressing an engaged audience in a blue-lit conference hall.\",\n",
      "  \"primary_brand\": \"AWS\",\n",
      "  \"logos\": [\n",
      "    {\n",
      "      \"logo_name\": \"AWS\",\n",
      "      \"brand_category\": \"company logo\",\n",
      "      \"timestamp\": \"00:00\",\n",
      "      \"duration\": \"throughout presentation\",\n",
      "      \"placement\": \"bottom right corner of the screen\",\n",
      "      \"description\": \"Small white AWS logo in the lower-right corner of the frame, consistently visible throughout the presentation.\",\n",
      "      \"prominence\": \"background\",\n",
      "      \"context\": \"Brand watermark during the entire presentation\"\n",
      "    }\n",
      "  ],\n",
      "  \"brand_mentions\": []\n",
      "}\n",
      "```\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing Video for Logo Recognition\\n\")\n",
    "print(\"Video: Andy-Jassy-on-Amazon-Nova.mp4\\n\")\n",
    "\n",
    "# Define JSON schema for logo detection results\n",
    "logo_detection_prompt = \"\"\"\n",
    "Analyze this executive presentation video and identify all brand logos, company branding, and visual brand elements.\n",
    "\n",
    "For tech presentations, pay special attention to:\n",
    "- Company logos (AWS, Amazon, partner companies)\n",
    "- Product logos and branding (Amazon Nova, AWS services, etc.)\n",
    "- Presentation slide branding and watermarks\n",
    "- Screen graphics and UI elements showing branded products\n",
    "- Background branding (stage backdrops, banners, displays)\n",
    "- Clothing or badge branding\n",
    "- Demo screens showing branded interfaces\n",
    "\n",
    "For each logo or brand element detected, provide:\n",
    "1. **Brand/Logo Name**: Specific name (e.g., \"AWS\", \"Amazon\", \"Amazon Nova\", \"Amazon Bedrock\")\n",
    "2. **Brand Category**: Type of branding (company logo, product logo, service name, presentation graphic, etc.)\n",
    "3. **Timestamp**: First clear appearance in MM:SS format\n",
    "4. **Duration**: How long it remains visible (\"throughout presentation\", \"5-10 seconds\", \"appears multiple times\", etc.)\n",
    "5. **Placement & Context**: Where it appears (slide header, product demo, speaker backdrop, clothing, etc.)\n",
    "6. **Visual Description**: Colors, size, prominence, and styling\n",
    "7. **Prominence Level**: How prominently featured (primary/secondary/background)\n",
    "\n",
    "Output in JSON format:\n",
    "{\n",
    "  \"presentation_context\": \"brief description of the presentation setting\",\n",
    "  \"primary_brand\": \"main company/product being presented\",\n",
    "  \"logos\": [\n",
    "    {\n",
    "      \"logo_name\": \"specific brand or product name\",\n",
    "      \"brand_category\": \"company logo | product logo | service name | presentation element\",\n",
    "      \"timestamp\": \"MM:SS\",\n",
    "      \"duration\": \"duration description\",\n",
    "      \"placement\": \"where the logo appears in frame\",\n",
    "      \"description\": \"detailed visual description including colors, size, and styling\",\n",
    "      \"prominence\": \"primary | secondary | background\",\n",
    "      \"context\": \"what's happening when this logo appears (e.g., 'shown during product announcement', 'visible on demo screen')\"\n",
    "    }\n",
    "  ],\n",
    "  \"brand_mentions\": [\n",
    "    {\n",
    "      \"brand_name\": \"brand mentioned verbally or in text\",\n",
    "      \"timestamp\": \"MM:SS\",\n",
    "      \"mention_type\": \"visual text | spoken | both\",\n",
    "      \"context\": \"context of the mention\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "If no recognizable logos are detected, return empty arrays.\n",
    "Provide ONLY the JSON output, no additional text.\n",
    "\"\"\"\n",
    "\n",
    "# Invoke model with logo detection prompt\n",
    "response_logo, content_logo= invoke_nova_video(\n",
    "    video_uri=video3_uri,\n",
    "    prompt=logo_detection_prompt,\n",
    "    temperature=0.2,  # Lower temperature for more consistent detection\n",
    "    bedrock_client=bedrock_client\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RAW JSON RESPONSE\")\n",
    "print(\"=\"*80)\n",
    "print(content_logo)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1b2c3-d4e5-6789-4567-901234567890",
   "metadata": {},
   "source": [
    "### Parsing and Displaying Logo Detection Results\n",
    "\n",
    "Now let's parse the JSON response and display the logo timeline in a formatted, human-readable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1b2c3d4-e5f6-7890-5678-012345678901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOGO RECOGNITION RESULTS\n",
      "================================================================================\n",
      "\n",
      "Video: Andy-Jassy-on-Amazon-Nova.mp4\n",
      "Total Logos Detected: 1\n",
      "\n",
      "1. AWS\n",
      "   First Appearance: 00:00\n",
      "   Duration: throughout presentation\n",
      "   Description: Small white AWS logo in the lower-right corner of the frame, consistently visible throughout the presentation.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Parse JSON response for logo detections\n",
    "try:\n",
    "    logo_data = parse_json_response(content_logo)\n",
    "    \n",
    "    # Display logo timeline with descriptions\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LOGO RECOGNITION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nVideo: Andy-Jassy-on-Amazon-Nova.mp4\")\n",
    "    \n",
    "    logos_detected = logo_data.get('logos', [])\n",
    "    print(f\"Total Logos Detected: {len(logos_detected)}\\n\")\n",
    "    \n",
    "    if len(logos_detected) > 0:\n",
    "        # Display each logo with details\n",
    "        for idx, logo_entry in enumerate(logos_detected, 1):\n",
    "            logo_name = logo_entry.get('logo_name', 'Unknown')\n",
    "            timestamp = logo_entry.get('timestamp', 'N/A')\n",
    "            duration = logo_entry.get('duration', 'Not specified')\n",
    "            description = logo_entry.get('description', 'No description')\n",
    "            \n",
    "            print(f\"{idx}. {logo_name}\")\n",
    "            print(f\"   First Appearance: {timestamp}\")\n",
    "            print(f\"   Duration: {duration}\")\n",
    "            print(f\"   Description: {description}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No recognizable brand logos were detected in this video.\\n\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Error parsing JSON response: {e}\")\n",
    "    print(\"The model may have returned text instead of pure JSON.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-b8c9-0123-8901-345678901234",
   "metadata": {},
   "source": [
    "### Logo Recognition Summary\n",
    "\n",
    "We've successfully demonstrated Nova Omni's logo recognition capabilities across two different videos.\n",
    "\n",
    "**Key Capabilities Demonstrated:**\n",
    "\n",
    "1. **Brand Identification**: Recognition of logos and trademarks in video frames\n",
    "2. **Temporal Tracking**: Precise timestamps for when logos first appear\n",
    "3. **Duration Estimation**: Understanding how long logos remain visible\n",
    "4. **Visual Description**: Detailed characteristics including colors, placement, and context\n",
    "5. **Structured Output**: JSON format for easy integration with analytics systems\n",
    "\n",
    "**Practical Applications:**\n",
    "\n",
    "- **Brand Visibility Reports**: Quantify brand exposure across video content\n",
    "- **Competitive Analysis**: Track competitor brand appearances in market research\n",
    "- **Sponsorship ROI**: Measure sponsor logo visibility and calculate exposure value\n",
    "- **Product Placement Verification**: Confirm contracted brand appearances\n",
    "- **Content Rights Management**: Identify unauthorized brand usage\n",
    "- **Advertising Analytics**: Measure brand presence in commercial content\n",
    "- **Market Intelligence**: Analyze brand trends in user-generated content\n",
    "\n",
    "**Integration Opportunities:**\n",
    "\n",
    "The structured JSON output enables:\n",
    "- Automated brand monitoring dashboards\n",
    "- Integration with marketing analytics platforms\n",
    "- Database storage for historical brand tracking\n",
    "- API endpoints for real-time logo detection services\n",
    "- Reporting systems for sponsorship and advertising teams\n",
    "\n",
    "**Considerations:**\n",
    "\n",
    "- Logo recognition accuracy depends on factors like video quality, logo size, and visibility\n",
    "- Partial or obscured logos may be more difficult to identify\n",
    "- Context and placement can affect recognition confidence\n",
    "- Regular testing with diverse content ensures consistent performance\n",
    "\n",
    "Logo recognition provides valuable insights for brand management, competitive intelligence, and content monetization strategies, making it an essential tool for modern video analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1d2e3-f4a5-6789-3456-890123456780",
   "metadata": {},
   "source": [
    "### Capabilities Summary\n",
    "\n",
    "Throughout this notebook, we've successfully demonstrated five comprehensive video understanding capabilities:\n",
    "\n",
    "**1. Video Summarization**\n",
    "- Generated concise summaries with key points for both test videos\n",
    "- Identified main events and moments in video content\n",
    "- Provided structured bullet-point summaries\n",
    "\n",
    "**2. Temporal Event Detection**\n",
    "- Detected environmental changes with precise timestamps\n",
    "- Identified character and object appearances\n",
    "- Recognized cinematographic elements and camera movements\n",
    "- All timestamps provided in human-readable MM:SS format\n",
    "\n",
    "**3. Structured Action Timeline**\n",
    "- Generated JSON-formatted chronological action lists\n",
    "- Created machine-readable timelines for programmatic processing\n",
    "- Enabled integration with downstream analytics systems\n",
    "\n",
    "**4. Content Moderation**\n",
    "- Analyzed visual content for explicit material\n",
    "- Examined audio content for toxic language\n",
    "- Provided severity assessments and detailed descriptions\n",
    "- Generated comprehensive moderation reports\n",
    "\n",
    "**5. Logo Recognition**\n",
    "- Identified brand logos and trademarks in video frames\n",
    "- Tracked logo appearances with timestamps and duration\n",
    "- Provided detailed visual descriptions of detected logos\n",
    "- Delivered structured JSON output for brand analytics\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "- **Environment Setup**: Successfully initialized AWS clients and configured S3 storage\n",
    "- **Helper Functions**: Created reusable utilities for video processing and cost tracking\n",
    "- **Video Upload**: Uploaded test videos to S3 for analysis\n",
    "- **Cost Tracking**: Monitored and calculated costs for all API invocations\n",
    "- **Error Handling**: Implemented robust error handling for AWS services and JSON parsing\n",
    "- **Structured Outputs**: Generated both human-readable and machine-readable results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4-a5b6-7890-4567-901234567891",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "Now that you've seen these capabilities in action, consider:\n",
    "\n",
    "1. **Experimenting with Your Own Videos**: Upload your own content to test these capabilities\n",
    "2. **Customizing Prompts**: Adjust prompts to focus on specific aspects relevant to your use case\n",
    "3. **Building Pipelines**: Integrate these capabilities into automated video processing workflows\n",
    "4. **Combining Capabilities**: Use multiple capabilities together for comprehensive video analysis\n",
    "5. **Scaling Up**: Process larger video libraries using batch processing techniques\n",
    "6. **Cost Optimization**: Use the cost tracking data to optimize your video analysis workflows\n",
    "7. **Integration**: Connect these capabilities to your existing systems via APIs\n",
    "8. **Advanced Use Cases**: Explore domain-specific applications like sports analytics, security monitoring, or content creation\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Amazon Nova Omni Documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/models-nova.html)\n",
    "- [Amazon Bedrock User Guide](https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html)\n",
    "- [Amazon Nova Samples Repository](https://github.com/aws-samples/amazon-nova-samples)\n",
    "- [Bedrock Pricing](https://aws.amazon.com/bedrock/pricing/)\n",
    "- [Amazon Bedrock API Reference](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html)\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Amazon Nova Omni provides powerful video understanding capabilities that can transform how you analyze and process video content. From simple summarization to complex logo recognition and content moderation, these capabilities enable you to extract valuable insights from video at scale.\n",
    "\n",
    "The combination of precise temporal understanding, structured outputs, and comprehensive cost tracking makes Nova Omni an excellent choice for production video analysis workflows. Whether you're building content moderation systems, brand monitoring tools, or automated video indexing solutions, Nova Omni provides the foundation for sophisticated video intelligence applications.\n",
    "\n",
    "Thank you for exploring Amazon Nova Omni's video understanding capabilities!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
