{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77cbd475",
   "metadata": {},
   "source": [
    "# üéÜ Amazon Nova Omni - Image Editing Capabilities\n",
    "\n",
    "Image editing is accomplished by passing a single image and a set of text instructions to the model. This example uses the Converse API. Image editing should allow you to do all of the following (and possibly more):\n",
    "\n",
    "* Add elements\n",
    "* Remove elements\n",
    "* Replace elements\n",
    "* Change elements (e.g. ‚Äúchange his shirt to red‚Äù)\n",
    "* Change the background\n",
    "* Extract or isolate an item in an image\n",
    "* Modify action/pose without changing the subject's identity (e.g. ‚ÄúMake this person smile‚Äù, ‚ÄúMake the man look to the left‚Äù)\n",
    "* Change the position of an item (e.g. \"Move the apple to the left half of the image\")\n",
    "* Change an image‚Äôs style\n",
    "* Change the lighting in an image\n",
    "\n",
    "\n",
    "## üéØ What You'll Build\n",
    "\n",
    "This hands-on section will guide you through how to use Nova Omni image editing capabilities with real-estate listing examples\n",
    "\n",
    "By the end of this workshop, you'll have:\n",
    "- ‚úÖ An understanding of how to edit images using Nova Omni\n",
    "- ‚úÖ Examples to get you started\n",
    "\n",
    "## Workshop Outline\n",
    "\n",
    "1. Object Addition to image - Virtual staging of a home\n",
    "2. Object removal - Remove unwanted objects from images. Remove cars and garbage from image\n",
    "3. Replace objects - Replace older furniture with newer good looking furniture\n",
    "4. Adjust/Improve the image - Improve unkept lawn by making  green grass enhancements\n",
    "5. Relighting - Replace dull or overcast skies with bright blue ones to make the exterior look more inviting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b2049",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports\n",
    "\n",
    "We will start setting the variables and helper functions for our tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_ID = \"us-west-2\"\n",
    "MODEL_ID = \"us.amazon.nova-2-omni-v1:0\"\n",
    "BEDROCK_ENDPOINT_URL = \"https://bedrock-runtime.us-west-2.amazonaws.com\"\n",
    "\n",
    "READ_TIMEOUT_SEC = 3 * 60\n",
    "MAX_RETRIES = 1\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import json\n",
    "import timeit\n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import Image, display\n",
    "import base64\n",
    "\n",
    "def analyze_image(image_path, text_input):\n",
    "    \"\"\"Analyze an image with text input using Amazon Bedrock Nova model.\"\"\"\n",
    "    # Read and encode image\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_data = image_file.read()\n",
    "    \n",
    "    # Determine image format\n",
    "    import os\n",
    "    ext = os.path.splitext(image_path)[1].lower()\n",
    "    image_format = 'jpeg' if ext in ['.jpg', '.jpeg'] else 'png' if ext == '.png' else 'jpeg'\n",
    "    \n",
    "    # Create Bedrock client\n",
    "    config = Config(\n",
    "        read_timeout=READ_TIMEOUT_SEC,\n",
    "        retries={\"max_attempts\": MAX_RETRIES},\n",
    "    )\n",
    "    \n",
    "    bedrock_runtime = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=REGION_ID,\n",
    "        #endpoint_url=BEDROCK_ENDPOINT_URL,\n",
    "        config=config,\n",
    "    )\n",
    "    \n",
    "    # Prepare request\n",
    "    request = {\n",
    "        \"modelId\": MODEL_ID,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"image\": {\"format\": image_format, \"source\": {\"bytes\": image_data}}},\n",
    "                    {\"text\": text_input},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        \"inferenceConfig\": {\"temperature\": 0.1, \"maxTokens\": 10000},\n",
    "    }\n",
    "    \n",
    "    # Make API call\n",
    "    response = bedrock_runtime.converse(**request)\n",
    "    return response\n",
    "\n",
    "def process_response(response, input_image_path):\n",
    "    \"\"\"Process and display response content with input and output images.\"\"\"\n",
    "    # Display input image first\n",
    "    print(\"== Input Image ==\")\n",
    "    display(Image(filename=input_image_path))\n",
    "    \n",
    "    response_content_list = response[\"output\"][\"message\"][\"content\"]\n",
    "\n",
    "    # Extract image content block\n",
    "    image_content = next(\n",
    "        (item for item in response_content_list if \"image\" in item),\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    # Extract text content block\n",
    "    text_content = next(\n",
    "        (item for item in response_content_list if \"text\" in item),\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if text_content:\n",
    "        print(\"== Text Output ==\")\n",
    "        print(text_content[\"text\"])\n",
    "\n",
    "    if image_content:\n",
    "        print(\"== Output Image ==\")\n",
    "        image_bytes = image_content[\"image\"][\"source\"][\"bytes\"]\n",
    "        display(Image(data=image_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3959110b",
   "metadata": {},
   "source": [
    "## 1-Object Addition to image - Virtual staging of a home\n",
    "In this example we show how to add objects to an existing image. We add furniture and decor to empty kitchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_PATH = \"img/1-kitchen-granite-island-empty.png\"\n",
    "TEXT_INPUT = \"You are given realestate listing image of an empty kitchen. Add bar stools to island, fruit bowl and some ceremic containers to kitchen for virual staging\"\n",
    "\n",
    "try:\n",
    "    start = timeit.default_timer()\n",
    "    response = analyze_image(INPUT_IMAGE_PATH, TEXT_INPUT)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "\n",
    "    print(f\"Request took {elapsed:.2f} seconds\")\n",
    "\n",
    "    process_response(response, INPUT_IMAGE_PATH)\n",
    "\n",
    "except ClientError as err:\n",
    "    print(\"Error occurred:\")\n",
    "    print(err)\n",
    "    if hasattr(err, \"response\"):\n",
    "        print(json.dumps(err.response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4955ade5",
   "metadata": {},
   "source": [
    "## 2-Remove Objects from an image - Property Cleanup\n",
    "In this example we show how to remove objects from an image. We remove cars and garbage from driveway of a home front elevation image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_PATH = \"img/2-home-with-cars-garbage-trashcans.png\"\n",
    "TEXT_INPUT = \"Remove cars, garbage and trash cans from image for realestate listing and generate image with empty driveway.\"\n",
    "\n",
    "try:\n",
    "    start = timeit.default_timer()\n",
    "    response = analyze_image(INPUT_IMAGE_PATH, TEXT_INPUT)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "\n",
    "    print(f\"Request took {elapsed:.2f} seconds\")\n",
    "\n",
    "    process_response(response, INPUT_IMAGE_PATH)\n",
    "\n",
    "except ClientError as err:\n",
    "    print(\"Error occurred:\")\n",
    "    print(err)\n",
    "    if hasattr(err, \"response\"):\n",
    "        print(json.dumps(err.response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da22d8",
   "metadata": {},
   "source": [
    "## 2a-Remove Objects from an image and match colors and shades - Property Cleanup\n",
    "Notice that when it removed cars (and garbage from the image in the prior step), some of the colors and shades might not be properly matched to their surroundings. We will improve the prompt with the clear and specific instructions so that the model can match the colors and shades properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_PATH = \"img/2-home-with-cars-garbage-trashcans.png\"\n",
    "TEXT_INPUT = \"Remove cars, remove garbage and remove trash cans from image for realestate listing and generate image with empty driveway.\" \\\n",
    "\" Match the colors properly after removing cars from driveway  and preserve other details of the home exactly as before\"\n",
    "\n",
    "try:\n",
    "    start = timeit.default_timer()\n",
    "    response = analyze_image(INPUT_IMAGE_PATH, TEXT_INPUT)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "\n",
    "    print(f\"Request took {elapsed:.2f} seconds\")\n",
    "\n",
    "    process_response(response, INPUT_IMAGE_PATH)\n",
    "\n",
    "except ClientError as err:\n",
    "    print(\"Error occurred:\")\n",
    "    print(err)\n",
    "    if hasattr(err, \"response\"):\n",
    "        print(json.dumps(err.response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d51379",
   "metadata": {},
   "source": [
    "## 3-Replace Objects from an image and match colors & shades to its surrounds properly - Virtual staging.\n",
    "We will replace old furniture from living room and place new furniture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_PATH = \"img/3-living-room-with-old-furniture.png\"\n",
    "TEXT_INPUT = \"Replace old furniture from living room and place newer furniture for realestate listing\"\n",
    "\n",
    "try:\n",
    "    start = timeit.default_timer()\n",
    "    response = analyze_image(INPUT_IMAGE_PATH, TEXT_INPUT)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "\n",
    "    print(f\"Request took {elapsed:.2f} seconds\")\n",
    "\n",
    "    process_response(response, INPUT_IMAGE_PATH)\n",
    "\n",
    "except ClientError as err:\n",
    "    print(\"Error occurred:\")\n",
    "    print(err)\n",
    "    if hasattr(err, \"response\"):\n",
    "        print(json.dumps(err.response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f8b3f9",
   "metadata": {},
   "source": [
    "## 3-Replace Objects from an image and match colors & shades to its surrounds properly - Virtual staging.\n",
    "We will improve the prompt with clear and specific details and guidelines so that Nova Omni and process them accurately. Notice the detailed prompt used and the output generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_PATH = \"img/3-living-room-with-old-furniture.png\"\n",
    "TEXT_INPUT = \"\"\"You are tasked with modernizing a living room for a real estate listing. Please replace ALL the following outdated items with contemporary, stylish alternatives that will appeal to today's buyers: \n",
    "ITEMS TO REPLACE:\n",
    "- Old sofas ‚Üí Replace with modern sectional or contemporary sofas in neutral colors (gray, beige, or white)\n",
    "- Outdated center table ‚Üí Replace with a sleek glass-top, marble, or minimalist wood coffee table\n",
    "- Old side tables ‚Üí Replace with modern end tables or accent tables with clean lines\n",
    "- Worn carpet ‚Üí Replace with a contemporary area rug with geometric patterns or solid neutral tones\n",
    "- Dated picture frames ‚Üí Replace with modern artwork in sleek frames or contemporary wall art\n",
    "\n",
    "STYLE REQUIREMENTS:\n",
    "- Use a cohesive modern design aesthetic throughout\n",
    "- Choose furniture with clean lines and contemporary silhouettes\n",
    "- Maintain neutral color palette (whites, grays, beiges) with subtle accent colors\n",
    "- Ensure proper scale and proportions for the room size\n",
    "- Keep the same room layout and lighting\n",
    "- Preserve the architectural elements (walls, windows, flooring)\n",
    "\n",
    "QUALITY STANDARDS:\n",
    "- All new furniture should look high-end and professionally staged\n",
    "- Maintain realistic lighting and shadows\n",
    "- Ensure color harmony and visual balance\n",
    "- Make the space feel inviting and move-in ready for potential buyers\n",
    "\n",
    "Generate an image that transforms this living room into a modern, market-ready space that would attract today's home buyers.\"\"\"\n",
    "\n",
    "try:\n",
    "    start = timeit.default_timer()\n",
    "    response = analyze_image(INPUT_IMAGE_PATH, TEXT_INPUT)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "\n",
    "    print(f\"Request took {elapsed:.2f} seconds\")\n",
    "\n",
    "    process_response(response, INPUT_IMAGE_PATH)\n",
    "\n",
    "except ClientError as err:\n",
    "    print(\"Error occurred:\")\n",
    "    print(err)\n",
    "    if hasattr(err, \"response\"):\n",
    "        print(json.dumps(err.response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359c32c",
   "metadata": {},
   "source": [
    "## 4-Background Modificaiton - Sky replacement (adding blue skies). \n",
    "Replaces dull or overcast skies with bright blue ones to make the exterior look more inviting. Note that just asking the model to \"Preserve all the other details as it is\" makes difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f4f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_PATH = \"img/4-front-elevation-cloudy-dark-sky.png\"\n",
    "TEXT_INPUT = \"Change the dark cloudy sky to clear blue sky in the image and improve brightness of the image. Preserve all other details as it is\"\n",
    "\n",
    "try:\n",
    "    start = timeit.default_timer()\n",
    "    response = analyze_image(INPUT_IMAGE_PATH, TEXT_INPUT)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "\n",
    "    print(f\"Request took {elapsed:.2f} seconds\")\n",
    "\n",
    "    process_response(response, INPUT_IMAGE_PATH)\n",
    "\n",
    "except ClientError as err:\n",
    "    print(\"Error occurred:\")\n",
    "    print(err)\n",
    "    if hasattr(err, \"response\"):\n",
    "        print(json.dumps(err.response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c80d48",
   "metadata": {},
   "source": [
    "## 5--Green grass enhancement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fab18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_PATH = \"img/5-unkept-lawn.png\"\n",
    "TEXT_INPUT = \"Improve the lawn in the image for realestate listing. Pay attention to walk way and steps, do not change their shape, just fix grass around them. \" \\\n",
    "\"Preserve other detail as it is.\"\n",
    "\n",
    "try:\n",
    "    start = timeit.default_timer()\n",
    "    response = analyze_image(INPUT_IMAGE_PATH, TEXT_INPUT)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "\n",
    "    print(f\"Request took {elapsed:.2f} seconds\")\n",
    "\n",
    "    process_response(response, INPUT_IMAGE_PATH)\n",
    "\n",
    "except ClientError as err:\n",
    "    print(\"Error occurred:\")\n",
    "    print(err)\n",
    "    if hasattr(err, \"response\"):\n",
    "        print(json.dumps(err.response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80565c8d",
   "metadata": {},
   "source": [
    "Congratulations on finishing the image editing lab! Feel free to try variation of the prompts in the notebook above and see how Nova Omni handles the image editing. The clearer and specific our prompts the better the editing quality of the images. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
