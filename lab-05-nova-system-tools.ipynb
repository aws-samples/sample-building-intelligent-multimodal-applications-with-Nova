{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ceeb77-77c8-413d-82a2-d4d0ddda62c1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# üßë‚Äçüíª Amazon Nova built-in System Tools: Code Interpreter & Web Grounding\n",
    "\n",
    "Amazon Nova 2 comes with two built-in system tools:\n",
    "1. Code Interpreter allows Amazon Nova to execute code\n",
    "2. Web Grounding enables Amazon Nova to search for real-time information on the web\n",
    "\n",
    "This notebook guides you how to use the Code Interpreter & Web Grounding with Amazon Nova 2 Omni.\n",
    "\n",
    "### üéØ What You'll Build\n",
    "\n",
    "By the end of this workshop, you will:\n",
    "- ‚úÖ Understand how the API for Code Interpreter & Web Grounding works\n",
    "- ‚úÖ Know how to use Code Interpreter & Web Grounding system tools\n",
    "- ‚úÖ Best practices for using system tools\n",
    "\n",
    "### Prerequisites\n",
    "- AWS Account\n",
    "- [IAM Permissions](https://docs.aws.amazon.com/bedrock/latest/userguide/security_iam_id-based-policy-examples.html) or an Amazon Bedrock [API Key](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_bedrock.html) to invoke Amazon Nova 2\n",
    "- Python 3.8+\n",
    "\n",
    "### Workshop Outline\n",
    "1. Setup and Configuration\n",
    "2. Quick start with Nova Code Interpreter\n",
    "3. Sample Use Cases that require Code Execution\n",
    "4. Quick start with Nova Web Grounding\n",
    "5. Sample Use Cases that benefit from Web Grounding\n",
    "6. Multi-Turn Conversation with Code Interpreter and Web Grounding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e8b7a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "This section covers the initial setup required to use Amazon Nova's Code Interpreter.\n",
    "We'll configure the AWS SDK (boto3) with appropriate settings for code execution tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28502aa",
   "metadata": {},
   "source": [
    "Before running this script, ensure you have the required dependencies installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a102f-a777-48d7-8bc1-659223c6e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be1dee-ef6b-4adb-b8d0-d8b057dd3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, JSON\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e774ca5a",
   "metadata": {},
   "source": [
    "The `create_boto3_client` helper function initializes a boto3 client for Amazon Bedrock Runtime\n",
    "with custom timeout configurations. These extended timeouts are crucial for Code Interpreter\n",
    "tasks that may take longer to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bfe24-fdf7-4df4-8a91-01d50fffd4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-west-2\"\n",
    "MODEL_ID = \"us.amazon.nova-2-omni-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe549f-ab2d-42d5-9a83-91b2cc210f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boto3_client():\n",
    "    client = boto3.client(\n",
    "        \"bedrock-runtime\",\n",
    "        region_name=REGION,\n",
    "        config=Config(\n",
    "            connect_timeout=3600,  # 60 minutes code interpreter might be more long running\n",
    "            read_timeout=3600,     # 60 minutes\n",
    "            retries={'max_attempts': 1}\n",
    "        )\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ab8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_client = create_boto3_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366cd79",
   "metadata": {},
   "source": [
    "## 2. Quick start with Nova Code Interpreter\n",
    "\n",
    "The Code Interpreter allows Amazon Nova to generate code that get's executed in a secure sandbox. \n",
    "This is useful for problems that require math, code writing or code review, and data analysis.\n",
    "\n",
    "### Architecture of Code Interpreter\n",
    "\n",
    "![](./img/Code-Interpreter.png)\n",
    "\n",
    "### Example Use Cases\n",
    "- Data Analysis, Data Visualization, Data-Driven Decision-Making\n",
    "- Code Assistant, Code Reviewer\n",
    "- Math\n",
    "- Other use cases that require reproducible computation rather than probablistic next token prediction\n",
    "\n",
    "### When not to use Code Interpreter\n",
    "- If you need to retrieve real-time information from the web. For such use cases we recommend to use the Amazon Nova web search system tool.\n",
    "- Currently, Amazon Nova Code Interpreter does not have access to your AWS resources. For automation tasks or to download from and upload data to an Amazon S3 bucket or database we recommend to use Amazon Bedrock AgentCore.\n",
    "\n",
    "\n",
    "To use Web Grounding, specify the `nova_code_interpreter` systemTool in your `toolConfig` block:\n",
    "\n",
    "```json\n",
    "\"toolConfig\": {\n",
    "    \"tools\": [\n",
    "        {\"systemTool\": {\"name\": \"nova_code_interpreter\"}}\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d759b-c736-4044-866e-2b7b5951808c",
   "metadata": {},
   "source": [
    "### Converse API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a62328f",
   "metadata": {},
   "source": [
    "This section demonstrates how to use Amazon Nova's Code Interpreter or Web Grounding through the Converse API.\n",
    "The Converse API provides a unified interface for interacting with foundation models,\n",
    "including support for system tools like the Code Interpreter and Web Grounding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f947d",
   "metadata": {},
   "source": [
    "The `construct_converse_payload` helper function constructs the payload required for the Converse API.\n",
    "It includes the model ID, messages, and other parameters like temperature, max tokens, and tool configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1517bc2-efaa-4038-9a7f-c3902a4606ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_converse_payload(model, messages, temperature, max_tokens, top_p = 0.9, system = None, reasoning_effort = None, tools = None):\n",
    "    inferenceConfig = {\n",
    "    }\n",
    "\n",
    "    if max_tokens != None:\n",
    "        inferenceConfig[\"maxTokens\"] = max_tokens\n",
    "\n",
    "    if temperature:\n",
    "        inferenceConfig[\"temperature\"] = temperature\n",
    "\n",
    "    if top_p:\n",
    "        inferenceConfig[\"topP\"] = top_p\n",
    "\n",
    "    tool_config = None\n",
    "    if tools:\n",
    "        tool_config = {\n",
    "            \"tools\": tools\n",
    "          }\n",
    "\n",
    "    additional_request_fields = {}\n",
    "    if reasoning_effort:\n",
    "        reasoning_config = {\n",
    "          \"type\": \"enabled\",\n",
    "          \"maxReasoningEffort\": reasoning_effort\n",
    "        }\n",
    "        additional_request_fields[\"reasoningConfig\"] = reasoning_config\n",
    "\n",
    "    request = {\n",
    "        \"modelId\":model, \n",
    "        \"messages\":messages, \n",
    "        \"inferenceConfig\":inferenceConfig,\n",
    "        \"toolConfig\":tool_config,\n",
    "        \"additionalModelRequestFields\":additional_request_fields\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        request[\"system\"] = system\n",
    "    \n",
    "    return request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c619928",
   "metadata": {},
   "source": [
    "The `amazon_bedrock_nova_converse` helper function is a wrapper that:\n",
    "1. Constructs the request payload\n",
    "2. Calls the Bedrock Runtime converse() API\n",
    "3. Extracts the text response from the model\n",
    "4. Returns both the text output and full response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a064d-26f9-4b2c-993f-9dff9a41ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon_bedrock_nova_converse(model, messages, temperature, max_tokens, top_p = 0.9, system = None, reasoning_effort = None, tools = None, bedrock_rt_client = None ):  \n",
    "    if not bedrock_rt_client:\n",
    "        bedrock_rt_client = create_boto3_client()\n",
    "\n",
    "    try:\n",
    "        request = construct_converse_payload(model, messages, temperature, max_tokens, top_p, system, reasoning_effort, tools)\n",
    "\n",
    "        model_response = bedrock_rt_client.converse(**request)\n",
    "        \n",
    "        return model_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(type(e), e)\n",
    "        return str(e), e\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be789b-8841-40e3-b760-ec7900d48baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_content_to_markdown(content_list, include_reasoning=False, include_tool_info=False):\n",
    "    \"\"\"\n",
    "    Formats complex Nova response content to markdown with inline citations.\n",
    "    \n",
    "    Args:\n",
    "        content_list: List of content items from the model response\n",
    "        include_reasoning: Whether to include reasoning content in output\n",
    "        include_tool_info: Whether to include tool use/result information\n",
    "    \n",
    "    Returns:\n",
    "        Formatted markdown string with citations\n",
    "    \"\"\"\n",
    "    markdown_parts = []\n",
    "    sources = []\n",
    "    citation_num = 0\n",
    "    \n",
    "    for item in content_list:\n",
    "        if 'text' in item:\n",
    "            markdown_parts.append(item['text'])\n",
    "            \n",
    "        elif 'citationsContent' in item:\n",
    "            for citation in item['citationsContent'].get('citations', []):\n",
    "                location = citation.get('location', {})\n",
    "                if 'web' in location:\n",
    "                    citation_num += 1\n",
    "                    url = location['web'].get('url', '')\n",
    "                    domain = location['web'].get('domain', url)\n",
    "                    sources.append({'num': citation_num, 'url': url, 'domain': domain})\n",
    "                    markdown_parts.append(f'[{citation_num}]')\n",
    "                    \n",
    "        elif 'reasoningContent' in item:\n",
    "            if include_reasoning:\n",
    "                reasoning = item['reasoningContent'].get('reasoningText', {}).get('text', '')\n",
    "                if reasoning:\n",
    "                    markdown_parts.append(\n",
    "                        f'\\n\\n<span><span style=\"color: rgb(150, 34, 73); font-weight: bold;\">&lt;details&gt;</span><span style=\"color: black; font-weight: normal;\">\\nReasoning\\n\\n{reasoning}\\n\\n</span><span style=\"color: rgb(150, 34, 73); font-weight: bold;\">&lt;/details&gt;</span><br><br></span>\\n\\n'\n",
    "                    )\n",
    "                    \n",
    "        elif 'toolUse' in item:\n",
    "            if include_tool_info:\n",
    "                tool = item['toolUse']\n",
    "                name = tool.get('name', 'unknown')\n",
    "                query = tool.get('input', {}).get('query', '')\n",
    "                markdown_parts.append(f'\\n\\n&gt; **Tool:** `{name}`\\n&gt; **Query:** \"{query}\"\\n\\n')\n",
    "                \n",
    "        elif 'toolResult' in item:\n",
    "            if include_tool_info:\n",
    "                status = item['toolResult'].get('status', '')\n",
    "                if status:\n",
    "                    markdown_parts.append(f'&gt; *Status: {status}*\\n\\n')\n",
    "    \n",
    "    # Combine text parts\n",
    "    output = ''.join(markdown_parts)\n",
    "    \n",
    "    # Add sources section with deduplication\n",
    "    if sources:\n",
    "        # Group citation numbers by URL\n",
    "        url_to_nums = {}\n",
    "        url_to_domain = {}\n",
    "        for src in sources:\n",
    "            url = src['url']\n",
    "            if url not in url_to_nums:\n",
    "                url_to_nums[url] = []\n",
    "                url_to_domain[url] = src['domain']\n",
    "            url_to_nums[url].append(str(src['num']))\n",
    "        \n",
    "        output += '\\n\\n---\\n\\n**Sources:**\\n'\n",
    "        for url, nums in url_to_nums.items():\n",
    "            nums_str = ', '.join(nums)\n",
    "            domain = url_to_domain[url]\n",
    "            # Use bold formatting instead of escaped brackets\n",
    "            output += f'\\n- **[{nums_str}]** [{domain}]({url})'\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9f928-eda5-4df8-99b7-1110dfb8290d",
   "metadata": {},
   "source": [
    "### Invoke Amazon Nova with Code Interpreter with the Converse API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d425890e",
   "metadata": {},
   "source": [
    "This example demonstrates the basic workflow of using Code Interpreter with the converse API. To give Amazon Nova access to the Code Interpreter you specify the `systemTool` parameter in the tools config. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcad3f6-e780-4d0b-a6f8-584493497fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"Print hello world using the code interpreter\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"systemTool\": {\n",
    "                \"name\": \"nova_code_interpreter\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "temperature = None\n",
    "top_p = None\n",
    "max_tokens = 1000\n",
    "reasoning_effort = None\n",
    "\n",
    "model_response = amazon_bedrock_nova_converse(MODEL_ID, messages, temperature, max_tokens, top_p, reasoning_effort=reasoning_effort, tools=tools, bedrock_rt_client=bedrock_client)\n",
    "content = model_response[\"output\"][\"message\"][\"content\"]\n",
    "output = format_content_to_markdown(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1a988",
   "metadata": {},
   "source": [
    "#### Understanding the Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca6e78-3ad1-4646-b297-67909a99f37a",
   "metadata": {},
   "source": [
    "The model response contains multiple layers of information. Let's examine each part.\n",
    "Here is the final output from Amazon Nova:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb0f4b-9dfa-454b-a6ff-8e36fd510b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe7086-53ad-4720-81ae-9a9e1841dbe6",
   "metadata": {},
   "source": [
    "In addition to the final output, you can examine the model response to understand\n",
    "what code was executed in the Code Interpreter. This is valuable for:\n",
    "- Debugging: See exactly what code was generated\n",
    "- Learning: Understand how the model approaches problems\n",
    "- Auditing: Track what code is being executed in your application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12d38b",
   "metadata": {},
   "source": [
    "Extract tool use and tool result from the response content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c5ec6-8222-407f-bf6b-589cbb180757",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_use = next((trace for trace in content if \"toolUse\" in trace), None)\n",
    "tool_result = next((trace for trace in content if \"toolResult\" in trace), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b99d314-969e-481d-ad34-e9b8c4568f92",
   "metadata": {},
   "source": [
    "The `toolUse` block shows what code Amazon Nova generated and sent to the Code Interpreter. The `toolUse` > `input` > `code` property contains the code that got executed in the Code Interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe7b5d-becb-4ee6-837f-32c7642fb483",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(tool_use, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a960e-582a-47e7-8799-e8499826d80d",
   "metadata": {},
   "source": [
    "The output of the Code Interpreter tool contains the logs from `stdOut` in the Code Interpreter environment and also any errors that occured in the Code Interpreter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb005422-088d-4d8a-a893-18498bdfa800",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(tool_result, expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670fe3c-8b44-43c8-80db-67e0bb7b6f80",
   "metadata": {},
   "source": [
    "### Converse API with Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f4409",
   "metadata": {},
   "source": [
    "Code Interpreter also works with streaming the response. Streaming allows you to receive the model's response incrementally as it's generated, rather than waiting for the complete response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4e54b",
   "metadata": {},
   "source": [
    "The `process_stream` helper function handles receiving the stream of output blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a4433-fb56-4b89-aa78-12b3143bac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stream(stream_response):\n",
    "    is_reasoning = False\n",
    "    is_text = False\n",
    "    is_toolUse = False\n",
    "    is_tool_result = False\n",
    "    \n",
    "    model_output = []  # List of content items matching format_content_to_markdown input\n",
    "    \n",
    "    # Temporary accumulators for streaming content\n",
    "    current_text = \"\"\n",
    "    current_reasoning = \"\"\n",
    "    current_tool_use = None\n",
    "    current_tool_use_input = \"\"\n",
    "    \n",
    "    def finalize_text():\n",
    "        nonlocal current_text\n",
    "        if current_text:\n",
    "            model_output.append({'text': current_text})\n",
    "            current_text = \"\"\n",
    "    \n",
    "    def finalize_reasoning():\n",
    "        nonlocal current_reasoning\n",
    "        if current_reasoning:\n",
    "            model_output.append({\n",
    "                'reasoningContent': {\n",
    "                    'reasoningText': {'text': current_reasoning}\n",
    "                }\n",
    "            })\n",
    "            current_reasoning = \"\"\n",
    "    \n",
    "    def finalize_tool_use():\n",
    "        nonlocal current_tool_use, current_tool_use_input\n",
    "        if current_tool_use:\n",
    "            if current_tool_use_input:\n",
    "                try:\n",
    "                    current_tool_use['input'] = json.loads(current_tool_use_input)\n",
    "                except json.JSONDecodeError:\n",
    "                    current_tool_use['input'] = {'raw': current_tool_use_input}\n",
    "            model_output.append({'toolUse': current_tool_use})\n",
    "            current_tool_use = None\n",
    "            current_tool_use_input = \"\"\n",
    "    \n",
    "    for message in stream_response[\"stream\"]:\n",
    "        if \"contentBlockStart\" in message:\n",
    "            start = message[\"contentBlockStart\"].get(\"start\", {})\n",
    "            \n",
    "            # Finalize any previous content blocks\n",
    "            finalize_text()\n",
    "            finalize_reasoning()\n",
    "            finalize_tool_use()\n",
    "            \n",
    "            if \"toolUse\" in start:\n",
    "                is_toolUse = True\n",
    "                is_text = False\n",
    "                is_reasoning = False\n",
    "                print(\"\\n\\n----MODEL RESPONSE: TOOL USE-----\\n\")\n",
    "                current_tool_use = start[\"toolUse\"].copy()\n",
    "                current_tool_use_input = \"\"\n",
    "                print(current_tool_use.get(\"name\", \"\"))\n",
    "\n",
    "        elif \"contentBlockDelta\" in message:\n",
    "            delta = message[\"contentBlockDelta\"][\"delta\"]\n",
    "\n",
    "            # Check for regular text\n",
    "            if \"text\" in delta:\n",
    "                if not is_text:\n",
    "                    finalize_reasoning()\n",
    "                    print(\"\\n\\n----MODEL RESPONSE: TEXT-----\\n\")\n",
    "                    is_text = True\n",
    "                    is_reasoning = False\n",
    "                    is_toolUse = False\n",
    "                text_chunk = delta[\"text\"]\n",
    "                current_text += text_chunk\n",
    "                print(text_chunk, end=\"\", flush=True)\n",
    "\n",
    "            # Check for reasoning content\n",
    "            elif \"reasoningContent\" in delta and \"text\" in delta[\"reasoningContent\"]:\n",
    "                if not is_reasoning:\n",
    "                    finalize_text()\n",
    "                    print(\"\\n\\n----MODEL RESPONSE: REASONING-----\\n\")\n",
    "                    is_text = False\n",
    "                    is_reasoning = True\n",
    "                    is_toolUse = False\n",
    "                reasoning_chunk = delta[\"reasoningContent\"][\"text\"]\n",
    "                current_reasoning += reasoning_chunk\n",
    "                print(reasoning_chunk, end=\"\", flush=True)\n",
    "\n",
    "            # Check for tool use input\n",
    "            elif \"toolUse\" in delta:\n",
    "                if \"input\" in delta[\"toolUse\"]:\n",
    "                    current_tool_use_input += delta[\"toolUse\"][\"input\"]\n",
    "                print(delta)\n",
    "                \n",
    "            # Check for tool result\n",
    "            elif \"toolResult\" in delta:\n",
    "                if not is_tool_result:\n",
    "                    print(\"\\n\\n----MODEL RESPONSE: TOOL RESULT-----\\n\")\n",
    "                    is_tool_result = True\n",
    "                    is_toolUse = False\n",
    "                model_output.append({'toolResult': delta[\"toolResult\"]})\n",
    "                print(delta)\n",
    "            \n",
    "            # Check for citations content\n",
    "            elif \"citationsContent\" in delta:\n",
    "                # Finalize text before citation so they stay paired\n",
    "                finalize_text()\n",
    "                is_text = False\n",
    "                model_output.append({'citationsContent': delta[\"citationsContent\"]})\n",
    "                \n",
    "        elif \"contentBlockStop\" in message:\n",
    "            # Finalize current content block\n",
    "            finalize_text()\n",
    "            finalize_reasoning()\n",
    "            finalize_tool_use()\n",
    "            # Reset state flags\n",
    "            is_text = False\n",
    "            is_reasoning = False\n",
    "            is_toolUse = False\n",
    "            is_tool_result = False\n",
    "            \n",
    "        elif \"messageStop\" in message:\n",
    "            print(\"\\n\\n----MODEL RESPONSE: messageStop-----\\n\")\n",
    "            print(json.dumps(message, indent=4))\n",
    "            \n",
    "        elif \"metadata\" in message:\n",
    "            print(\"\\n\\n----MODEL RESPONSE: metadata-----\\n\")\n",
    "            print(json.dumps(message, indent=4))\n",
    "    \n",
    "    # Finalize any remaining accumulated content\n",
    "    finalize_text()\n",
    "    finalize_reasoning()\n",
    "    finalize_tool_use()\n",
    "    \n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827be2bb",
   "metadata": {},
   "source": [
    "Similar to the non-streaming version, but calls `converse_stream` instead. The function returns a stream object that must be iterated to receive events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e247305-5c9a-4507-a787-d61d638fd616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon_bedrock_nova_converse_streaming(model, messages, temperature, max_tokens, top_p = 0.9, system = None, reasoning_effort = None, tools = None, bedrock_rt_client = None ):  \n",
    "    if not bedrock_rt_client:\n",
    "        bedrock_rt_client = create_boto3_client()\n",
    "\n",
    "    try:\n",
    "        request = construct_converse_payload(model, messages, temperature, max_tokens, top_p, system, reasoning_effort, tools)\n",
    "\n",
    "        model_response = bedrock_rt_client.converse_stream(**request)\n",
    "        \n",
    "        return model_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(type(e), e)\n",
    "        return e\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443dd7c9-1a64-44a4-bb20-b7f91aef7dac",
   "metadata": {},
   "source": [
    "### Invoke Amazon Nova with Code Interpreter using the Converse Streaming API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d7ba81",
   "metadata": {},
   "source": [
    "Next you will invoke the Converse Streaming API with Code Interpreter system tool configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311f646-1956-431f-be3a-e7114960ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"Calculate 7^6 using the code interpreter\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"systemTool\": {\n",
    "                \"name\": \"nova_code_interpreter\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "temperature = None\n",
    "top_p = None\n",
    "max_tokens = 1000\n",
    "reasoning_effort = None\n",
    "\n",
    "response = amazon_bedrock_nova_converse_streaming(MODEL_ID, messages, temperature, max_tokens, top_p, reasoning_effort=reasoning_effort, tools=tools, bedrock_rt_client=bedrock_client)\n",
    "model_output = process_stream(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a25d5b-869b-455c-8145-b2c64be1c7bb",
   "metadata": {},
   "source": [
    "The final response from Amazon Nova is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea63e4e-aabe-47ca-b31a-a70f50b82d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = format_content_to_markdown(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16fce8c-2fff-4a61-b994-f23a8f3eda79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3693e0-e292-4275-bea8-ec64a0ecad38",
   "metadata": {},
   "source": [
    "## 3. Sample Use Cases that require Code execution\n",
    "\n",
    "This section demonstrates scenarios where Code Interpreter excels. These examples showcase the power of combining LLM reasoning with code execution for tasks that require precise computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0429d6b6-8dfb-4010-b3b5-8c5d63d43837",
   "metadata": {},
   "source": [
    "#### Solving Polynomial Equations\n",
    "\n",
    "Polynomial equations often have complex or multiple roots that are difficult to find even for reasoning models. Code Interpreter can use numerical methods (like NumPy's roots function) to find all solutions, including complex roots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4e1f1-0a14-4c6c-8f5f-38dba7842cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"Use Python to solve the polynomial equation: z^6 + z^4 + z^3 + z^2 + 1 = 0. Find the exact roots. Format your response in markdown.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"systemTool\": {\n",
    "                \"name\": \"nova_code_interpreter\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "temperature = None\n",
    "top_p = None\n",
    "max_tokens = 5000\n",
    "reasoning_effort = None\n",
    "\n",
    "model_response = amazon_bedrock_nova_converse(MODEL_ID, messages, temperature, max_tokens, top_p, reasoning_effort=reasoning_effort, tools=tools, bedrock_rt_client=bedrock_client)\n",
    "content = model_response[\"output\"][\"message\"][\"content\"]\n",
    "\n",
    "output = format_content_to_markdown(content, include_reasoning=False, include_tool_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d82ab-0a7b-4ec4-aa06-4210aaa60070",
   "metadata": {},
   "source": [
    "Here is the solution for the polynomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefed7cb-1012-4829-a21b-4e87758c2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b7f76-d934-4782-a329-497773fea43f",
   "metadata": {},
   "source": [
    "#### Statistical Hypothesis Testing\n",
    "\n",
    "Statistical analysis is a perfect use case for Code Interpreter because it requires:\n",
    "- Precise mathematical calculations\n",
    "- Standard statistical libraries (scipy, numpy)\n",
    "- Amazon Nova's capability to interpret the results in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c78aae9-40fa-4cb1-817c-a80b3508716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"\"\"I have two datasets of student test scores. Perform a t-test to determine if there's a statistically significant difference between them at Œ±=0.05 confidence level.\n",
    "\n",
    "Group A: [78, 85, 92, 88, 79, 91, 84, 87, 90, 82]\n",
    "Group B: [72, 75, 81, 69, 74, 78, 71, 76, 73, 70]\n",
    "\"\"\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"systemTool\": {\n",
    "                \"name\": \"nova_code_interpreter\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "temperature = None\n",
    "top_p = None\n",
    "max_tokens = 10000\n",
    "reasoning_effort = None\n",
    "\n",
    "model_response = amazon_bedrock_nova_converse(MODEL_ID, messages, temperature, max_tokens, top_p, reasoning_effort=reasoning_effort, tools=tools, bedrock_rt_client=bedrock_client)\n",
    "content = model_response[\"output\"][\"message\"][\"content\"]\n",
    "\n",
    "output = format_content_to_markdown(content, include_reasoning=False, include_tool_info=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a3826-51ac-44bd-adb1-1b6dea9064bc",
   "metadata": {},
   "source": [
    "Here is the output of the statistical analysis that Amazon Nova conducted using the code interpreter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2315d3d-4caf-4431-b45b-8fcc1a9a3080",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStatistical analysis results:\")\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b2bd21-4440-460e-a4f6-306839228f7f",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be09b0a-4050-41d6-a8c4-b9fa699511f9",
   "metadata": {},
   "source": [
    "## 4. Quick start with Nova Web Grounding\n",
    "\n",
    "Web Grounding enhances Amazon Nova models by connecting them to real-time information beyond their knowledge cutoff, resulting in more accurate and reliable responses with cited sources. This built-in tool automatically retrieves and incorporates publicly available information to reduce AI hallucinations and improve accuracy.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "When Web Grounding is enabled, the model intelligently determines if a search is needed to improve the response. If required, it automatically performs one or more searches, analyzes the results, and synthesizes the information into a final response complete with citations to its sources. All searches stay within AWS infrastructure and never reach the broader internet, prioritizing trustworthy sources and filtering malicious content.\n",
    "\n",
    "### Example Use Cases\n",
    "\n",
    "- **Knowledge-Based Chat Assistants**: Provide up-to-date answers with source citations for customer inquiries\n",
    "- **Research Assistants**: Access current information and factual data with transparent source attribution\n",
    "- **Content Generation Tools**: Create content grounded in real-time, cited information\n",
    "- **Customer Support Applications**: Deliver accurate responses based on the latest available information\n",
    "- **News and Current Events**: Answer questions about recent developments with proper citations\n",
    "\n",
    "### When Not to Use Web Grounding\n",
    "\n",
    "- **For Private or Internal Data**: Web Grounding only accesses publicly available information. For proprietary data, use Retrieval Augmented Generation (RAG) with Amazon Bedrock Knowledge Bases.\n",
    "\n",
    "### Availability and Requirements\n",
    "\n",
    "Web Grounding is currently available in US regions.\n",
    "\n",
    "To use Web Grounding, specify the `nova_grounding` systemTool in your `toolConfig` block:\n",
    "\n",
    "```json\n",
    "\"toolConfig\": {\n",
    "    \"tools\": [\n",
    "        {\"systemTool\": {\"name\": \"nova_grounding\"}}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "**Important**: You must retain and display citations and links in the output you provide to your end users.\n",
    "\n",
    "### Invoke Amazon Nova with Web Grounding with the Converse API\n",
    "\n",
    "This example demonstrates the basic workflow of using Web Grounding with the converse API. To give Amazon Nova access to Web Grounding you specify `nova_grounding` in the `systemTool` parameter in the tools config. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f039509b-48d0-400f-bd95-373b27784541",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"What is the price of Amazon Stock?\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"systemTool\": {\n",
    "                \"name\": \"nova_grounding\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "temperature = None\n",
    "top_p = None\n",
    "max_tokens = 1000\n",
    "reasoning_effort = None\n",
    "\n",
    "model_response = amazon_bedrock_nova_converse(MODEL_ID, messages, temperature, max_tokens, top_p, reasoning_effort=reasoning_effort, tools=tools, bedrock_rt_client=bedrock_client)\n",
    "content = model_response[\"output\"][\"message\"][\"content\"]\n",
    "output = format_content_to_markdown(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c66488-5328-49b4-aeb4-64155dd24da6",
   "metadata": {},
   "source": [
    "#### Understanding the Response\n",
    "\n",
    "Let's take a look at the different items that are returned in the response.\n",
    "\n",
    "Here is the **final response** that Amazon Nova generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53706c2-f17a-4613-bf54-42187661d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37fba8-bf77-41ba-971a-2045eccbbe90",
   "metadata": {},
   "source": [
    "You can also **see more details** about the web grounding tool call.\n",
    "The response from the output contains the query that Amazon Nova constructed to send to the web grounding system in the `toolUse` > `input` > `query` parameter.\n",
    "\n",
    "If you take a look at the response from the API before formatting it to Markdown you can see how the text that Amazon Nova has generated is interleaved with the `citationsContent` blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320fadc-302f-4e76-93d6-48cbcfde91c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53761547-7c8f-450e-b9a5-06de486147a5",
   "metadata": {},
   "source": [
    "### Invoke Amazon Nova with Web Grounding using the Converse Streaming API \n",
    "\n",
    "Next you will invoke the Converse Streaming API with Web Grounding system tool configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a991e-2bb1-48de-b4d9-345757a21a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"What is the weather in Seattle today?\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"systemTool\": {\n",
    "                \"name\": \"nova_grounding\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "temperature = None\n",
    "top_p = None\n",
    "max_tokens = 1000\n",
    "reasoning_effort = None\n",
    "\n",
    "response = amazon_bedrock_nova_converse_streaming(MODEL_ID, messages, temperature, max_tokens, top_p, reasoning_effort=reasoning_effort, tools=tools, bedrock_rt_client=bedrock_client)\n",
    "model_output = process_stream(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55513b-b2ba-4f50-a4c6-cdce7f0ce655",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = format_content_to_markdown(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793be79-25cc-4b3e-8aeb-def01c0a9a62",
   "metadata": {},
   "source": [
    "The final response is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243df9bb-8c3f-4d53-981d-770386d8634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f21f43-80d3-4d56-9763-acff5cdd6b9a",
   "metadata": {},
   "source": [
    "## 5. Sample Use Cases that benefit from Web Grounding\n",
    "\n",
    "This section demonstrates scenarios where Web Grounding is useful. Before Web Grounding such capabilities would require maintaining a custom Retrieval-Augmented Generation (RAG) pipeline of financial reports or the integration with another API. Now with Web Grounding as a system tool public real-time information can be retrieved out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e9ae20-c8dc-4c40-9fa3-2c5a8a0b6b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"Find the latest earnings report from Amazon and analyze main trends. Respond in markdown\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"systemTool\": {\n",
    "                \"name\": \"nova_grounding\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "temperature = None\n",
    "top_p = None\n",
    "max_tokens = None\n",
    "reasoning_effort = \"medium\"\n",
    "\n",
    "model_response = amazon_bedrock_nova_converse(MODEL_ID, messages, temperature, max_tokens, top_p, reasoning_effort=reasoning_effort, tools=tools, bedrock_rt_client=bedrock_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a81263-8dd1-4b09-80c9-2ad9a889c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_content_to_markdown(model_response[\"output\"][\"message\"][\"content\"], include_reasoning=False, include_tool_info=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd0c30-9958-4073-b608-73fba75d3525",
   "metadata": {},
   "source": [
    "You can combine the reasoning capabilities of Amazon Nova Omni with Web Grounding to have Amazon Nova reason through conflicting or divisive information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3be2d6-f0a1-4f88-ba1d-8159f0db0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"Pineapple on Pizza.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"systemTool\": {\n",
    "                \"name\": \"nova_grounding\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "temperature = None\n",
    "top_p = None\n",
    "max_tokens = None\n",
    "reasoning_effort = \"high\"\n",
    "\n",
    "model_response = amazon_bedrock_nova_converse(MODEL_ID, messages, temperature, max_tokens, top_p, reasoning_effort=reasoning_effort, tools=tools, bedrock_rt_client=bedrock_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b3a3f-5093-46e4-9dee-bdf69a031994",
   "metadata": {},
   "source": [
    "Below is the final response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5d318-9c4d-4da7-bc14-7c71bc90ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_content_to_markdown(model_response[\"output\"][\"message\"][\"content\"], include_reasoning=False, include_tool_info=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca74115-cefd-4a10-b2de-d2c6687ed29b",
   "metadata": {},
   "source": [
    "## 6. Multi-Turn Conversation with Code Interpreter and Web Grounding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe6556d-2401-49ba-b850-ca4d8e2ec9a5",
   "metadata": {},
   "source": [
    "This section demonstrates a realistic business scenario where a coffee shop owner uses data analysis to reduce waste and make informed decisions.\n",
    "\n",
    "In this example, we'll simulate a conversation with Mar√≠a, a coffee shop owner who wants to understand and reduce her daily pastry waste. The conversation progresses from initial problem identification to data analysis and decision-making.\n",
    "\n",
    "The multi-turn conversation combines both Code Interpreter with Web Grounding  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ee5e2-ce18-4b1d-9b6f-70d349052059",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"I'm throwing away so many pastries at the end of each day. It breaks my heart and wastes money. What can I do about this?\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "tools = [\n",
    "        {\n",
    "            \"systemTool\": {\n",
    "                \"name\": \"nova_code_interpreter\"\n",
    "            }\n",
    "        },\n",
    "    {\n",
    "            \"systemTool\": {\n",
    "                \"name\": \"nova_grounding\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "system = [{ \"text\": \"You are a helpful assistant. Use the Code Interpreter or Web Grounding tool when available and appropriate. Keep your answers short. Format your responses in Markdown.\" }]\n",
    "\n",
    "temperature = 0.7\n",
    "top_p = 0.9\n",
    "max_tokens = 1000\n",
    "\n",
    "model_response = amazon_bedrock_nova_converse(MODEL_ID, messages, temperature, max_tokens, top_p, system=system, tools=tools, bedrock_rt_client=bedrock_client)\n",
    "\n",
    "content = model_response[\"output\"][\"message\"][\"content\"]\n",
    "output = format_content_to_markdown(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19519819-c506-4a53-9a5b-e0b9b0be5447",
   "metadata": {},
   "source": [
    "Turn 1 - Initial consultation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f45f20-9053-4781-9450-ed3ac9cdef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78d48b-d3f0-4ac8-94b6-403f997ee1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"text\": output}]\n",
    "})\n",
    "\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\n",
    "        \"text\": \"That's helpful! I'm wondering if my waste is actually abnormal though. I throw away about 8-12 pastries per day. I order the same amount every week from my supplier‚Äî4 dozen croissants, 3 dozen muffins, 2 dozen danishes. What's the typical waste percentage for bakeries, and how do I compare?\"\n",
    "    }]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a652384-9bac-44f7-bd17-09af0dd316be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = amazon_bedrock_nova_converse(MODEL_ID, messages, temperature, max_tokens, top_p, tools=tools, bedrock_rt_client=bedrock_client)\n",
    "content = model_response[\"output\"][\"message\"][\"content\"]\n",
    "output = format_content_to_markdown(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5673a-cba8-452d-b816-4b7984bf42e5",
   "metadata": {},
   "source": [
    "Turn 2 - Understanding the pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86133b0-ebb8-4105-973e-ef8515899ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0886c1c-8c27-41e6-9b94-ca450d34253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "        {\n",
    "            \"systemTool\": {\n",
    "                \"name\": \"nova_code_interpreter\"\n",
    "            }\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060f531-ccd0-443f-a9f6-094df888cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"text\": output}]\n",
    "})\n",
    "\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\n",
    "        \"text\": \"\"\"Okay, I tracked what I throw away for a week. Here's what I threw away each day:\n",
    "\n",
    "Monday: 6 croissants, 4 muffins\n",
    "\n",
    "Tuesday: 5 croissants, 3 muffins\n",
    "\n",
    "Wednesday: 8 croissants, 5 muffins, 2 danishes\n",
    "\n",
    "Thursday: 4 croissants, 2 muffins, 1 danish\n",
    "\n",
    "Friday: 2 croissants, 1 muffin\n",
    "\n",
    "Saturday: 1 croissant, 0 muffins\n",
    "\n",
    "Sunday: 3 croissants, 2 muffins\n",
    "\n",
    "Each croissant costs me $1.50, muffins $1.20, and danishes $1.80. Calculate my total weekly losses, break it down by day and pastry type, and show me which days are worst. Also, if I reduced my orders to match this waste pattern, how much would I save annually?\"\"\"\n",
    "    }]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a2501-3679-472c-9de7-9baaee68ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = amazon_bedrock_nova_converse(MODEL_ID, messages, temperature, max_tokens, top_p, tools=tools, bedrock_rt_client=bedrock_client)\n",
    "content = model_response[\"output\"][\"message\"][\"content\"]\n",
    "output = format_content_to_markdown(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73b8d0-58c1-4525-b50f-db7160da946b",
   "metadata": {},
   "source": [
    "Turn 3 - Waste analysis with calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52c8ce-7e8a-43d2-b870-74b427b73a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909e988-bd2f-4bec-a71e-634b644cec47",
   "metadata": {},
   "source": [
    "Let's examine the code that was executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589cd990-13a8-4038-ab4d-c585ef5c1ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = model_response['output']['message']['content']\n",
    "tool_use = next((trace for trace in content if \"toolUse\" in trace), None)\n",
    "if tool_use and \"input\" in tool_use[\"toolUse\"]:\n",
    "    print(\"Code executed by Amazon Nova:\")\n",
    "    print(tool_use[\"toolUse\"][\"input\"][\"snippet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c256c-d22e-4374-893a-2d72d8d0b0e1",
   "metadata": {},
   "source": [
    "## System Tools Pricing\n",
    "\n",
    "You can review the pricing for Web Grounding and Code Interpreter in the Amazon Nova model pricing details sections on [https://aws.amazon.com/bedrock/pricing/](https://aws.amazon.com/bedrock/pricing/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074c973c-f478-40dd-a3ff-f4eb73ed9fe3",
   "metadata": {},
   "source": [
    "## üéØ Workshop Summary\n",
    "\n",
    "You've learnt how to use built in system tools like Code Interpreter and Web Grounding with Amazon Nova 2 Omni.\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [User Guide for Amazon Nova - Web Grounding](https://docs.aws.amazon.com/nova/latest/userguide/grounding.html)\n",
    "- [User Guide for Amazon Nova - Code Interpreter](https://docs.aws.amazon.com/nova/latest/userguide/grounding.html)\n",
    "\n",
    "Great job completing this workshop! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
