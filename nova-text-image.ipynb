{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77cbd475",
   "metadata": {},
   "source": [
    "# Text to text and text to image with Amazon Nova\n",
    "\n",
    "This hands-on section will guide you through how to use Nova text and image generation\n",
    "\n",
    "## üéØ What You'll Build\n",
    "\n",
    "By the end of this workshop, you'll have:\n",
    "- ‚úÖ An understanding of how to generate text and images with Nova\n",
    "- ‚úÖ Examples to get you started\n",
    "\n",
    "## Workshop Outline\n",
    "1. Text generation\n",
    "2. Built-in reasoning\n",
    "3. Web grounding\n",
    "4. Image generation with text rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b2049",
   "metadata": {},
   "source": [
    "## Text generation\n",
    "\n",
    "During this section, you will send a requests to generate text with word count requirements and structure output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -r requirementsv2.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd713b9",
   "metadata": {},
   "source": [
    "Set variables and helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "282d6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "import json\n",
    "\n",
    "REGION_ID = \"us-west-2\"\n",
    "MODEL_ID = \"us.amazon.nova-2-omni-v1:0\"\n",
    "\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name=REGION_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e838d23",
   "metadata": {},
   "source": [
    "### Word count\n",
    "Nova omni has improved capabilities for counting words in the output. Next, you will send a request to generate a response in 10 or less words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0a974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Text Output ==\n",
      "Basic program printing \"Hello World\".\n"
     ]
    }
   ],
   "source": [
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": \"In *less than 10 words**, describe what a Hello World program is.\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0.5, \"maxTokens\": 512},\n",
    "}\n",
    "response = bedrock_runtime.converse(**request)\n",
    "response_content_list = response[\"output\"][\"message\"][\"content\"]\n",
    "\n",
    "# Extract text content block\n",
    "text_content = next(\n",
    "    (item for item in response_content_list if \"text\" in item),\n",
    "    None,\n",
    ")\n",
    "\n",
    "if text_content:\n",
    "    print(\"== Text Output ==\")\n",
    "    print(text_content[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a54bf",
   "metadata": {},
   "source": [
    "### Use output formats\n",
    "Nova Omni can generate outputs in specific formats such as JSON. The following code generates a list of grocery products using a JSON schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46defc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Respond using this schema:\n",
    "{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"item_id\": {\n",
    "      \"type\": \"integer\"\n",
    "    },\n",
    "    \"name\": {\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    \"description\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"item_id\", \"name\", \"description\"]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"system\": [{\"text\": system_prompt}],\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": \"Return multiple every day grocery items\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0.5, \"maxTokens\": 1024},\n",
    "}\n",
    "response = bedrock_runtime.converse(**request)\n",
    "response_content_list = response[\"output\"][\"message\"][\"content\"]\n",
    "\n",
    "# Extract text content block\n",
    "text_content = next(\n",
    "    (item for item in response_content_list if \"text\" in item),\n",
    "    None,\n",
    ")\n",
    "\n",
    "if text_content:\n",
    "    # Validate JSON output\n",
    "    json_output = json.loads(text_content[\"text\"].replace(\"```\",\"\").replace(\"json\", \"\"))\n",
    "    print(\"== JSON Output ==\")\n",
    "    print(json.dumps(json_output, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9248aea",
   "metadata": {},
   "source": [
    "## Built-in Reasoning\n",
    "Instead of asking Nova to think step by step, you can enable a parameter to set the reasoning config enable with a high effort as shown in the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5faac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Respond using this schema:\n",
    "{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"result\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"result\"]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "text_prompt=\"\"\"\n",
    "Explain why plants need sunlight, water, and carbon dioxide to survive.\n",
    "\"\"\"\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"system\": [{\"text\": system_prompt}],\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": text_prompt\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"additionalModelRequestFields\":{'reasoningConfig': {'type': 'enabled', 'maxReasoningEffort': 'high'}}\n",
    "}\n",
    "response = bedrock_runtime.converse(**request)\n",
    "response_content_list = response[\"output\"][\"message\"][\"content\"]\n",
    "\n",
    "# Extract text content block\n",
    "text_content = next(\n",
    "    (item for item in response_content_list if \"text\" in item),\n",
    "    None,\n",
    ")\n",
    "\n",
    "if text_content:\n",
    "    # Validate JSON output\n",
    "    json_output = json.loads(text_content[\"text\"].replace(\"```\",\"\").replace(\"json\", \"\"))\n",
    "    print(\"== Result ==\") \n",
    "    print(json_output['result'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a137650f",
   "metadata": {},
   "source": [
    "## Web grounding\n",
    "Web Grounding provides developers with a turnkey Retrieval Augmented Generation (RAG) option that allows the Amazon Nova foundation models to intelligently decide when to retrieve and incorporate relevant up-to-date information based on the context of the prompt. This is done by defining a tool called nova_grounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_prompt=\"\"\"\n",
    "What is the status of Bedrock Agent Core?\n",
    "\"\"\"\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": text_prompt\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"toolConfig\": {\n",
    "          \"tools\":[ \n",
    "              {\n",
    "                \"systemTool\": {\n",
    "                   \"name\": \"nova_grounding\" # Enables the model to search real-time information\n",
    "                 }\n",
    "              }\n",
    "          ]\n",
    "     },\n",
    "    \"inferenceConfig\": {\"maxTokens\": 10240},\n",
    "}\n",
    "response = bedrock_runtime.converse(**request)\n",
    "response_content_list = response[\"output\"][\"message\"][\"content\"]\n",
    "print(response_content_list)\n",
    "# Extract text content block\n",
    "text_content = next(\n",
    "    (item for item in response_content_list if \"text\" in item),\n",
    "    None,\n",
    ")\n",
    "\n",
    "tool_use = next(\n",
    "    (item for item in response_content_list if \"toolUse\" in item),\n",
    "    None,\n",
    ")\n",
    "print(\"== Tools ==\")\n",
    "print(json.dumps(tool_use,indent=2)) \n",
    "if text_content:\n",
    "    print(\"== Text Output ==\")\n",
    "    print(text_content['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c494b659",
   "metadata": {},
   "source": [
    "## Image generation with text rendering\n",
    "In this section, you will send a request to Nova to generate an image of a new car model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d81000",
   "metadata": {},
   "source": [
    "### Setup variables and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd629e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import timeit\n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import Image, display\n",
    "system_prompt = \"You are a professional automotive CGI designer. All the images generated have to be in 1:1 ratio.\"\n",
    "prompt = \"\"\"\n",
    "You must create a high-resolution photorealistic render based on the following instructions without deviating from the details:\n",
    "1. The subject is an All-New SUV, 'Sensory Captain Chairs' grade, white exterior. \n",
    "2. The scene should place the vehicle on a scenic beach backdrop during golden hour with realistic reflections and lighting. \n",
    "3. Overlay the exact text ‚ÄúThe Pinnacle of Luxury Experience‚Äù in an elegant, premium serif font at the lower third of the image. \n",
    "4. Maintain a cinematic composition, showcasing the full car exterior in a three-quarter front view.\n",
    "Now generate the image of the car\n",
    "\"\"\"\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"system\": [{\"text\": system_prompt}],\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                 {\"text\": prompt} \n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0.5, \"maxTokens\": 512},\n",
    "}\n",
    "\n",
    "# Start the request\n",
    "start = timeit.default_timer()\n",
    "response = bedrock_runtime.converse(**request)\n",
    "elapsed = timeit.default_timer() - start\n",
    "print(f\"Request took {elapsed:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635da32",
   "metadata": {},
   "source": [
    "Because Nova Omni has multiple output modalities, it can include images and text in the response. The following code checks if an image is returned by the model, get the bytes and display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59640d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    response_content_list = response[\"output\"][\"message\"][\"content\"]\n",
    "\n",
    "    # Extract image content block\n",
    "    image_content = next(\n",
    "        (item for item in response_content_list if \"image\" in item),\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if image_content:\n",
    "        print(\"== Image Output ==\")\n",
    "        image_bytes = image_content[\"image\"][\"source\"][\"bytes\"]\n",
    "        generated_image = Image(data=image_bytes)\n",
    "        display(generated_image)\n",
    "\n",
    "except ClientError as err:\n",
    "    print(\"Error occurred:\")\n",
    "    print(err)\n",
    "    if hasattr(err, \"response\"):\n",
    "        print(json.dumps(err.response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825b29e",
   "metadata": {},
   "source": [
    "## üéØ Workshop Summary\n",
    "\n",
    "Congratulations! You've successfully completed the text to text and text to image workshop with Amazon Nova. Great job! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
