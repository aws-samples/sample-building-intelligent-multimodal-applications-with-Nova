{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77cbd475",
   "metadata": {},
   "source": [
    "# Text to text and text to image with Amazon Nova\n",
    "\n",
    "This hands-on section will guide you through how to use Nova text and image generation\n",
    "\n",
    "## üéØ What You'll Build\n",
    "\n",
    "By the end of this workshop, you'll have:\n",
    "- ‚úÖ An understanding of how to generate text and images with Nova\n",
    "- ‚úÖ Examples to get you started\n",
    "\n",
    "## Workshop Outline\n",
    "1. Text generation\n",
    "2. Built-in reasoning\n",
    "3. Image generation with text rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b2049",
   "metadata": {},
   "source": [
    "## Text generation\n",
    "\n",
    "During this section, you will send requests to generate text with word count requirements and structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (it can take several minutes)\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd713b9",
   "metadata": {},
   "source": [
    "Set variables and helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282d6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "import json\n",
    "\n",
    "REGION_ID = \"us-west-2\"\n",
    "MODEL_ID = \"us.amazon.nova-2-omni-v1:0\"\n",
    "\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name=REGION_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e838d23",
   "metadata": {},
   "source": [
    "### Word count\n",
    "You can control how long the response should be using natural language in the input prompt, in addition to the maxToken paramater. In the following example, you will send a request to generate a response in 10 or less words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0a974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": \"In *less than 10 words**, describe what a Hello World program is.\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0.5, \"maxTokens\": 512},\n",
    "}\n",
    "response = bedrock_runtime.converse(**request)\n",
    "response_content_list = response[\"output\"][\"message\"][\"content\"]\n",
    "\n",
    "# Extract text content block\n",
    "text_content = next(\n",
    "    (item for item in response_content_list if \"text\" in item),\n",
    "    None,\n",
    ")\n",
    "\n",
    "if text_content:\n",
    "    print(\"== Text Output ==\")\n",
    "    print(text_content[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a54bf",
   "metadata": {},
   "source": [
    "### Use output formats\n",
    "Nova can generate outputs in specific formats such as JSON. Having structured output provides development teams with a better experience because less code is needed to parse the output of the model. The following code generates a list of grocery products using a JSON schema, with variable types and required fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46defc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Respond using this schema:\n",
    "{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"item_id\": {\n",
    "      \"type\": \"integer\"\n",
    "    },\n",
    "    \"name\": {\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    \"description\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"item_id\", \"name\", \"description\"]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"system\": [{\"text\": system_prompt}],\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": \"Return multiple every day grocery items\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0.5, \"maxTokens\": 1024},\n",
    "}\n",
    "response = bedrock_runtime.converse(**request)\n",
    "response_content_list = response[\"output\"][\"message\"][\"content\"]\n",
    "\n",
    "# Extract text content block\n",
    "text_content = next(\n",
    "    (item for item in response_content_list if \"text\" in item),\n",
    "    None,\n",
    ")\n",
    "\n",
    "if text_content:\n",
    "    # Validate JSON output\n",
    "    json_output = json.loads(text_content[\"text\"].replace(\"```\",\"\").replace(\"json\", \"\"))\n",
    "    print(\"== JSON Output ==\")\n",
    "    print(json.dumps(json_output, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9248aea",
   "metadata": {},
   "source": [
    "## Built-in Reasoning\n",
    "Instead of asking Nova to think step by step, you can enable a parameter to enable the reasoning config, with a high effort. Having this as a setting simplifies the prompt and can be validated using the reasoningContent section in the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5faac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Respond using this schema:\n",
    "{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"result\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"result\"]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "text_prompt=\"\"\"\n",
    "Explain why plants need sunlight, water, and carbon dioxide to survive.\n",
    "\"\"\"\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"system\": [{\"text\": system_prompt}],\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": text_prompt\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"additionalModelRequestFields\":{'reasoningConfig': {'type': 'enabled', 'maxReasoningEffort': 'high'}}\n",
    "}\n",
    "response = bedrock_runtime.converse(**request)\n",
    "response_content_list = response[\"output\"][\"message\"][\"content\"]\n",
    "reasoning_content = next(\n",
    "    (item for item in response_content_list if \"reasoningContent\" in item),\n",
    "    None,\n",
    ")\n",
    "print(\"== Reasoning ==\")\n",
    "print(json.dumps(reasoning_content,indent=2)) \n",
    "# Extract text content block\n",
    "text_content = next(\n",
    "    (item for item in response_content_list if \"text\" in item),\n",
    "    None,\n",
    ")\n",
    "\n",
    "if text_content:\n",
    "    # Validate JSON output\n",
    "    json_output = json.loads(text_content[\"text\"].replace(\"```\",\"\").replace(\"json\", \"\"))\n",
    "    print(\"== Result ==\") \n",
    "    print(json_output['result'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c494b659",
   "metadata": {},
   "source": [
    "## Image generation with text rendering\n",
    "In this section, you will send a request to Nova to generate an image of a new car model. The prompt goes into the details that the model needs to consider while generating the image and what text should be rendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd629e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import timeit\n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import Image, display\n",
    "system_prompt = \"You are a professional automotive CGI designer. All the images generated have to be in 1:1 ratio.\"\n",
    "prompt = \"\"\"\n",
    "You must create a high-resolution photorealistic render based on the following instructions without deviating from the details:\n",
    "1. The subject is an All-New SUV, 'Sensory Captain Chairs' grade, white exterior. \n",
    "2. The scene should place the vehicle on a scenic beach backdrop during golden hour with realistic reflections and lighting. \n",
    "3. Overlay the exact text ‚ÄúThe Pinnacle of Luxury Experience‚Äù in an elegant, premium serif font at the lower third of the image. \n",
    "4. Maintain a cinematic composition, showcasing the full car exterior in a three-quarter front view.\n",
    "Now generate the image of the car\n",
    "\"\"\"\n",
    "request = {\n",
    "    \"modelId\": MODEL_ID,\n",
    "    \"system\": [{\"text\": system_prompt}],\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                 {\"text\": prompt} \n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\"temperature\": 0.5, \"maxTokens\": 512},\n",
    "}\n",
    "\n",
    "# Start the request\n",
    "start = timeit.default_timer()\n",
    "response = bedrock_runtime.converse(**request)\n",
    "elapsed = timeit.default_timer() - start\n",
    "print(f\"Request took {elapsed:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635da32",
   "metadata": {},
   "source": [
    "Because Nova has multiple output modalities, it can include images and text in the response. The following code checks if an image is returned by the model, gets the bytes and displays it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59640d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    response_content_list = response[\"output\"][\"message\"][\"content\"]\n",
    "\n",
    "    # Extract image content block\n",
    "    image_content = next(\n",
    "        (item for item in response_content_list if \"image\" in item),\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if image_content:\n",
    "        print(\"== Image Output ==\")\n",
    "        image_bytes = image_content[\"image\"][\"source\"][\"bytes\"]\n",
    "        generated_image = Image(data=image_bytes)\n",
    "        display(generated_image)\n",
    "\n",
    "except ClientError as err:\n",
    "    print(\"Error occurred:\")\n",
    "    print(err)\n",
    "    if hasattr(err, \"response\"):\n",
    "        print(json.dumps(err.response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825b29e",
   "metadata": {},
   "source": [
    "## üéØ Workshop Summary\n",
    "\n",
    "Congratulations! You've successfully completed the text to text and text to image workshop with Amazon Nova. Great job! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
