{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Amazon Nova Multimodal RAG Workshop\n",
    "\n",
    "Welcome to this hands-on workshop where you'll learn to build a complete multimodal RAG system using Amazon Nova!\n",
    "\n",
    "## ğŸ¯ What You'll Learn\n",
    "\n",
    "By the end of this workshop, you'll be able to:\n",
    "- âœ… **Embed multiple images** using Nova Multimodal Embeddings\n",
    "- âœ… **Perform cross-modal search** (find images with text, text with images)\n",
    "- âœ… **Build tool calling systems** that integrate multimodal search\n",
    "- âœ… **Use S3 Vectors** for efficient similarity search\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "## ğŸ“‹ Prerequisites\n",
    "\n",
    "- AWS Account with Bedrock access\n",
    "- Basic understanding of embeddings and vector search\n",
    "\n",
    "Let's get started! ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "First, let's install the required packages and set up our AWS connections.\n",
    "\n",
    "**What we're doing:**\n",
    "- Installing Python packages for AWS SDK and image processing\n",
    "- Initializing Bedrock clients for Nova models\n",
    "- Setting up S3 Vectors for efficient similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install boto3 numpy pandas pillow opencv-python\n",
    "!pip install -r requirementsv2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Initialize AWS clients\n",
    "bedrock = boto3.client('bedrock-runtime', region_name='us-west-2')\n",
    "bedrock_embedding = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "s3vectors = boto3.client('s3vectors', region_name='us-east-1')\n",
    "\n",
    "# Configuration\n",
    "NOVA_MODEL_ID = \"us.amazon.nova-2-omni-v1:0\"\n",
    "NOVA_EMBED_MODEL_ID = \"amazon.nova-2-multimodal-embeddings-v1:0\"\n",
    "EMBEDDING_DIM = 1024  # Using 1024 dimensions for optimal performance\n",
    "VECTOR_BUCKET = f'nova-workshop-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "INDEX_NAME = 'multimodal-search'\n",
    "\n",
    "print(\"ğŸš€ AWS clients initialized!\")\n",
    "print(f\"ğŸ“Š Nova Model: {NOVA_MODEL_ID}\")\n",
    "print(f\"ğŸ¨ Embedding Model: {NOVA_EMBED_MODEL_ID}\")\n",
    "print(f\"ğŸ“¦ Vector Bucket: {VECTOR_BUCKET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Nova Multimodal Embeddings\n",
    "\n",
    "Amazon Nova Multimodal Embeddings is a breakthrough model that can create unified embeddings for text, images, video, and audio content.\n",
    "\n",
    "**Key Benefits:**\n",
    "- **Unified Model**: Single model handles all content types\n",
    "- **Cross-Modal Search**: Find images with text queries and vice versa\n",
    "- **High Performance**: State-of-the-art accuracy with cost efficiency\n",
    "- **Easy Integration**: Simple API for complex multimodal tasks\n",
    "\n",
    "**How Embeddings Work:**\n",
    "1. Convert content (text/image) into numerical vectors\n",
    "2. Similar content gets similar vectors\n",
    "3. Use mathematical distance to find related content\n",
    "\n",
    "Let's create our embedding class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NovaMultimodalEmbeddings:\n",
    "    \"\"\"\n",
    "    Wrapper for Amazon Nova Multimodal Embeddings\n",
    "    Handles text and image embeddings with error handling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.bedrock = bedrock_embedding\n",
    "        self.model_id = NOVA_EMBED_MODEL_ID\n",
    "        self.embedding_dim = EMBEDDING_DIM\n",
    "    \n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate embeddings for text content\"\"\"\n",
    "        request_body = {\n",
    "            \"schemaVersion\": \"nova-multimodal-embed-v1\",\n",
    "            \"taskType\": \"SINGLE_EMBEDDING\",\n",
    "            \"singleEmbeddingParams\": {\n",
    "                \"embeddingPurpose\": \"GENERIC_RETRIEVAL\",\n",
    "                \"embeddingDimension\": self.embedding_dim,\n",
    "                \"text\": {\"truncationMode\": \"NONE\", \"value\": text}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = self.bedrock.invoke_model(\n",
    "            body=json.dumps(request_body),\n",
    "            modelId=self.model_id,\n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response[\"body\"].read())\n",
    "        return result[\"embeddings\"][0][\"embedding\"]\n",
    "    \n",
    "    def embed_image(self, image_path: str) -> List[float]:\n",
    "        \"\"\"Generate embeddings for image content\"\"\"\n",
    "        # Read and encode image to base64\n",
    "        with open(image_path, 'rb') as f:\n",
    "            image_bytes = base64.b64encode(f.read()).decode('utf-8')\n",
    "        \n",
    "        request_body = {\n",
    "            \"schemaVersion\": \"nova-multimodal-embed-v1\",\n",
    "            \"taskType\": \"SINGLE_EMBEDDING\",\n",
    "            \"singleEmbeddingParams\": {\n",
    "                \"embeddingPurpose\": \"GENERIC_RETRIEVAL\",\n",
    "                \"embeddingDimension\": self.embedding_dim,\n",
    "                \"image\": {\n",
    "                    \"detailLevel\": \"DOCUMENT_IMAGE\",\n",
    "                    \"format\": \"png\",\n",
    "                    \"source\": {\"bytes\": image_bytes}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = self.bedrock.invoke_model(\n",
    "            body=json.dumps(request_body),\n",
    "            modelId=self.model_id,\n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response[\"body\"].read())\n",
    "        return result[\"embeddings\"][0][\"embedding\"]\n",
    "\n",
    "# Initialize our embeddings class\n",
    "embeddings = NovaMultimodalEmbeddings()\n",
    "print(\"ğŸ¨ Nova Multimodal Embeddings ready!\")\n",
    "\n",
    "# Test with a simple example\n",
    "try:\n",
    "    test_embedding = embeddings.embed_text(\"Hello world\")\n",
    "    print(f\"âœ… Test successful! Embedding has {len(test_embedding)} dimensions\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Test failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: S3 Vectors Setup\n",
    "\n",
    "S3 Vectors provides efficient storage and similarity search for embeddings. Think of it as a specialized database for vector operations.\n",
    "\n",
    "**Why S3 Vectors?**\n",
    "- **Scalable**: Handle millions of embeddings\n",
    "- **Fast**: Optimized for similarity search\n",
    "- **Cost-effective**: Pay only for what you use\n",
    "- **Integrated**: Works seamlessly with AWS services\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Vector Bucket**: Like a database that stores embeddings\n",
    "- **Index**: Like a table with specific schema for fast search\n",
    "- **Cosine Distance**: Mathematical way to measure similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_s3_vectors():\n",
    "    \"\"\"\n",
    "    Create S3 Vectors bucket and index for storing embeddings\n",
    "    \n",
    "    This function:\n",
    "    1. Creates a vector bucket (like creating a database)\n",
    "    2. Creates an index (like creating a table with specific schema)\n",
    "    3. Configures for 1024-dimensional embeddings with cosine similarity\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create vector bucket (like creating a database)\n",
    "        print(\"ğŸ“¦ Creating vector bucket...\")\n",
    "        s3vectors.create_vector_bucket(\n",
    "            vectorBucketName=VECTOR_BUCKET,\n",
    "            encryptionConfiguration={'sseType': 'AES256'}  # Encrypt data at rest\n",
    "        )\n",
    "        print(f\"âœ… Created vector bucket: {VECTOR_BUCKET}\")\n",
    "        \n",
    "        # Create index (like creating a table with specific schema)\n",
    "        print(\"ğŸ” Creating search index...\")\n",
    "        s3vectors.create_index(\n",
    "            vectorBucketName=VECTOR_BUCKET,\n",
    "            indexName=INDEX_NAME,\n",
    "            dimension=EMBEDDING_DIM,  # Must match Nova's embedding dimension\n",
    "            dataType='float32',       # Data type for embeddings\n",
    "            distanceMetric='cosine'   # How to measure similarity\n",
    "        )\n",
    "        print(f\"âœ… Created index: {INDEX_NAME}\")\n",
    "        print(f\"ğŸ“Š Configured for {EMBEDDING_DIM}-dimensional embeddings\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        if 'already exists' in str(e):\n",
    "            print(f\"â„¹ï¸ Vector store already exists: {VECTOR_BUCKET}\")\n",
    "            return True\n",
    "        print(f\"âŒ Error creating S3 Vectors: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Set up our vector store\n",
    "print(\"ğŸ—ï¸ Setting up S3 Vectors for embedding storage...\")\n",
    "if setup_s3_vectors():\n",
    "    print(\"\\nğŸ‰ S3 Vectors ready for embeddings!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ S3 Vectors setup failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Discover and Process Content\n",
    "\n",
    "Now let's discover images in our img folder and prepare content for embedding. We'll work with both text descriptions and actual images.\n",
    "\n",
    "**What we're doing:**\n",
    "- Finding image files in the img folder\n",
    "- Creating text descriptions for different products\n",
    "- Preparing metadata for better search results\n",
    "\n",
    "**Content Strategy:**\n",
    "- Mix text and images for cross-modal search\n",
    "- Use descriptive text that relates to images\n",
    "- Add metadata for filtering and categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover available images in img folder\n",
    "IMG_FOLDER = 'img'\n",
    "print(f\"ğŸ” Discovering images in {IMG_FOLDER} folder...\")\n",
    "\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.webp')\n",
    "\n",
    "# Check if img folder exists\n",
    "if os.path.exists(IMG_FOLDER) and os.path.isdir(IMG_FOLDER):\n",
    "    image_files = [f for f in os.listdir(IMG_FOLDER) if f.lower().endswith(image_extensions)]\n",
    "    # Create full paths for the images\n",
    "    image_paths = [os.path.join(IMG_FOLDER, f) for f in image_files]\n",
    "    \n",
    "    print(f\"ğŸ–¼ï¸ Found {len(image_files)} images in {IMG_FOLDER} folder:\")\n",
    "    for i, img in enumerate(image_files[:10], 1):  # Show first 10\n",
    "        print(f\"   {i}. ğŸ“¸ {img}\")\n",
    "    \n",
    "    if len(image_files) > 10:\n",
    "        print(f\"   ... and {len(image_files) - 10} more\")\n",
    "else:\n",
    "    print(f\"âš ï¸ {IMG_FOLDER} folder not found. Creating empty list.\")\n",
    "    image_files = []\n",
    "    image_paths = []\n",
    "\n",
    "if not image_files:\n",
    "    print(f\"âš ï¸ No images found in {IMG_FOLDER} folder. Please add some .jpg, .jpeg, or .png files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample content with rich descriptions\n",
    "# This simulates a product catalog with both text and images\n",
    "\n",
    "print(\"ğŸ“ Creating sample content for multimodal search...\")\n",
    "\n",
    "content_data = [\n",
    "    # Text descriptions (like product descriptions)\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"content\": \"High-quality leather boots perfect for outdoor hiking and adventures\",\n",
    "        \"key\": \"text_boots_outdoor\",\n",
    "        \"category\": \"footwear\",\n",
    "        \"description\": \"Product description for outdoor boots\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"content\": \"Comfortable running sneakers with modern athletic design and cushioning\",\n",
    "        \"key\": \"text_sneakers_athletic\",\n",
    "        \"category\": \"footwear\",\n",
    "        \"description\": \"Product description for athletic sneakers\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"content\": \"Amazon Nova multimodal foundation model for text, image, and video processing\",\n",
    "        \"key\": \"text_nova_model\",\n",
    "        \"category\": \"technology\",\n",
    "        \"description\": \"Information about Nova AI model\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"content\": \"Premium footwear collection featuring various styles for different occasions\",\n",
    "        \"key\": \"text_footwear_collection\",\n",
    "        \"category\": \"footwear\",\n",
    "        \"description\": \"General footwear collection overview\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Add images to our content (limit to first 10 for workshop)\n",
    "print(\"ğŸ–¼ï¸ Adding images to content collection...\")\n",
    "for i, (img_file, img_path) in enumerate(zip(image_files[:10], image_paths[:10])):\n",
    "    # Determine category based on filename\n",
    "    category = \"footwear\" if any(word in img_file.lower() for word in ['boot', 'sneaker', 'shoe']) else \"product\"\n",
    "    \n",
    "    content_data.append({\n",
    "        \"type\": \"image\",\n",
    "        \"content\": img_path,  # Use full path instead of just filename\n",
    "        \"key\": f\"image_{img_file.split('.')[0]}\",\n",
    "        \"category\": category,\n",
    "        \"description\": f\"Product image: {img_file} from {IMG_FOLDER} folder\"\n",
    "    })\n",
    "\n",
    "print(f\"\\nğŸ“Š Content collection prepared:\")\n",
    "print(f\"   ğŸ“ Text items: {len([c for c in content_data if c['type'] == 'text'])}\")\n",
    "print(f\"   ğŸ–¼ï¸ Image items: {len([c for c in content_data if c['type'] == 'image'])}\")\n",
    "print(f\"   ğŸ“¦ Total items: {len(content_data)}\")\n",
    "\n",
    "# Show sample content\n",
    "print(\"\\nğŸ“‹ Sample content:\")\n",
    "for item in content_data[:3]:\n",
    "    print(f\"   â€¢ [{item['type'].upper()}] {item['content'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate and Store Embeddings\n",
    "\n",
    "This is where the magic happens! We'll convert both text and images into embeddings using Nova, then store them in S3 Vectors.\n",
    "\n",
    "**Key Concept:** Embeddings are numerical representations that capture the semantic meaning of content. Similar content will have similar embeddings.\n",
    "\n",
    "**Process Flow:**\n",
    "1. **For Text**: Send text to Nova â†’ Get 1024-dimensional vector\n",
    "2. **For Images**: Encode image â†’ Send to Nova â†’ Get 1024-dimensional vector\n",
    "3. **Store**: Save vectors with metadata in S3 Vectors\n",
    "4. **Index**: Enable fast similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and store all content as embeddings\n",
    "vectors = []\n",
    "successful_embeddings = 0\n",
    "failed_embeddings = 0\n",
    "\n",
    "print(\"ğŸ”„ Processing content and generating embeddings...\")\n",
    "print(\"This may take a few moments depending on the number of items.\\n\")\n",
    "\n",
    "for i, item in enumerate(content_data, 1):\n",
    "    print(f\"Processing {i}/{len(content_data)}: {item['type']} - {item['content'][:50]}...\")\n",
    "    \n",
    "    try:\n",
    "        # Generate embedding based on content type\n",
    "        if item[\"type\"] == \"text\":\n",
    "            embedding = embeddings.embed_text(item[\"content\"])\n",
    "            print(f\"   âœ“ Generated text embedding ({len(embedding)} dimensions)\")\n",
    "            \n",
    "        elif item[\"type\"] == \"image\" and os.path.exists(item[\"content\"]):\n",
    "            embedding = embeddings.embed_image(item[\"content\"])\n",
    "            print(f\"   âœ“ Generated image embedding ({len(embedding)} dimensions)\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ Skipping: {item['content']} (file not found)\")\n",
    "            failed_embeddings += 1\n",
    "            continue\n",
    "        \n",
    "        # Create vector with rich metadata for S3 Vectors\n",
    "        vector = {\n",
    "            \"key\": item[\"key\"],\n",
    "            \"data\": {\"float32\": embedding},\n",
    "            \"metadata\": {\n",
    "                \"type\": item[\"type\"],\n",
    "                \"content\": item[\"content\"],\n",
    "                \"category\": item.get(\"category\", \"general\"),\n",
    "                \"description\": item.get(\"description\", \"\"),\n",
    "                \"embedding_model\": NOVA_EMBED_MODEL_ID\n",
    "            }\n",
    "        }\n",
    "        vectors.append(vector)\n",
    "        successful_embeddings += 1\n",
    "        print(f\"   âœ“ Added to vector collection\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error processing {item['content']}: {str(e)}\")\n",
    "        failed_embeddings += 1\n",
    "    \n",
    "    print()  # Empty line for readability\n",
    "\n",
    "print(f\"ğŸ“Š Embedding Generation Summary:\")\n",
    "print(f\"   âœ… Successful: {successful_embeddings}\")\n",
    "print(f\"   âŒ Failed: {failed_embeddings}\")\n",
    "print(f\"   ğŸ“¦ Total vectors ready: {len(vectors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all vectors in S3 Vectors\n",
    "if vectors:\n",
    "    try:\n",
    "        print(f\"ğŸ’¾ Storing {len(vectors)} embeddings in S3 Vectors...\")\n",
    "        \n",
    "        s3vectors.put_vectors(\n",
    "            vectorBucketName=VECTOR_BUCKET,\n",
    "            indexName=INDEX_NAME,\n",
    "            vectors=vectors\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ‰ Successfully stored {len(vectors)} embeddings in S3 Vectors!\")\n",
    "        print(f\"ğŸ“Š Storage Details:\")\n",
    "        print(f\"   ğŸ“¦ Bucket: {VECTOR_BUCKET}\")\n",
    "        print(f\"   ğŸ” Index: {INDEX_NAME}\")\n",
    "        print(f\"   ğŸ“ Embedding dimension: {EMBEDDING_DIM}\")\n",
    "        print(f\"   ğŸ¯ Distance metric: cosine\")\n",
    "        print(f\"   ğŸ” Ready for similarity search!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error storing vectors: {str(e)}\")\n",
    "        print(\"Please check your AWS permissions and try again.\")\n",
    "else:\n",
    "    print(\"âš ï¸ No vectors to store. Please check the content processing step above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Multimodal Search\n",
    "\n",
    "Now for the exciting part - searching across different content types! You can use text to find images, or find similar text content.\n",
    "\n",
    "**Cross-Modal Search Examples:**\n",
    "- Search \"leather boots\" â†’ Find boot images AND text descriptions\n",
    "- Search \"running\" â†’ Find sneaker images and athletic text\n",
    "- Search \"outdoor\" â†’ Find hiking-related content across all types\n",
    "\n",
    "**How It Works:**\n",
    "1. Convert your search query to an embedding\n",
    "2. Compare with stored embeddings using cosine similarity\n",
    "3. Return the most similar content (regardless of type!)\n",
    "4. Filter by content type if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimodal_search(query: str, content_type: str = \"all\", top_k: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Search across all content types using text query\n",
    "    \n",
    "    Args:\n",
    "        query: Text query to search for\n",
    "        content_type: Filter by 'text', 'image', or 'all'\n",
    "        top_k: Number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of search results with metadata and similarity scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ” Searching for: '{query}'\")\n",
    "        print(f\"ğŸ“Š Content filter: {content_type}\")\n",
    "        print(f\"ğŸ¯ Max results: {top_k}\")\n",
    "        \n",
    "        # Step 1: Convert query to embedding\n",
    "        print(\"\\n1ï¸âƒ£ Converting query to embedding...\")\n",
    "        query_embedding = embeddings.embed_text(query)\n",
    "        print(f\"   âœ“ Generated query embedding ({len(query_embedding)} dimensions)\")\n",
    "        \n",
    "        # Step 2: Search S3 Vectors for similar embeddings\n",
    "        print(\"\\n2ï¸âƒ£ Searching S3 Vectors for similar content...\")\n",
    "        response = s3vectors.query_vectors(\n",
    "            vectorBucketName=VECTOR_BUCKET,\n",
    "            indexName=INDEX_NAME,\n",
    "            queryVector={\"float32\": query_embedding},\n",
    "            topK=top_k * 2,  # Get extra results for filtering\n",
    "            returnDistance=True,\n",
    "            returnMetadata=True\n",
    "        )\n",
    "        \n",
    "        results = response.get(\"vectors\", [])\n",
    "        print(f\"   âœ“ Found {len(results)} initial results\")\n",
    "        \n",
    "        # Step 3: Filter by content type if specified\n",
    "        if content_type != \"all\":\n",
    "            print(f\"\\n3ï¸âƒ£ Filtering results by content type: {content_type}\")\n",
    "            filtered_results = [r for r in results if r.get(\"metadata\", {}).get(\"type\") == content_type]\n",
    "            print(f\"   âœ“ {len(filtered_results)} results after filtering\")\n",
    "            results = filtered_results\n",
    "        \n",
    "        # Step 4: Return top results\n",
    "        final_results = results[:top_k]\n",
    "        print(f\"\\nâœ… Returning top {len(final_results)} results\")\n",
    "        \n",
    "        return final_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Search error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def display_search_results(query: str, results: List[Dict], show_details: bool = True):\n",
    "    \"\"\"Display search results in a user-friendly format\"\"\"\n",
    "    print(f\"\\nğŸ” Search Results for: '{query}'\")\n",
    "    print(f\"ğŸ“Š Found {len(results)} results\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No results found. Try a different search term.\")\n",
    "        return\n",
    "    \n",
    "    icons = {\"text\": \"ğŸ“\", \"image\": \"ğŸ–¼ï¸\", \"video\": \"ğŸ¥\", \"audio\": \"ğŸµ\"}\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        metadata = result.get(\"metadata\", {})\n",
    "        content_type = metadata.get(\"type\", \"unknown\")\n",
    "        content = metadata.get(\"content\", \"N/A\")\n",
    "        category = metadata.get(\"category\", \"general\")\n",
    "        description = metadata.get(\"description\", \"\")\n",
    "        \n",
    "        # Calculate similarity score (1 - distance = similarity)\n",
    "        similarity = 1 - result.get(\"distance\", 0)\n",
    "        icon = icons.get(content_type, \"â“\")\n",
    "        \n",
    "        print(f\"{i}. {icon} [{content_type.upper()}] Similarity: {similarity:.3f}\")\n",
    "        print(f\"   Content: {content}\")\n",
    "        \n",
    "        if show_details:\n",
    "            print(f\"   Category: {category}\")\n",
    "            if description:\n",
    "                print(f\"   Description: {description}\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "print(\"ğŸ” Multimodal search functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test our multimodal search with different queries!\n",
    "test_queries = [\n",
    "    {\"query\": \"leather boots\", \"type\": \"all\", \"description\": \"Find all content about leather boots\"},\n",
    "    {\"query\": \"home with car\", \"type\": \"image\", \"description\": \"find homes only with car\"},\n",
    "    {\"query\": \"outdoor activities\", \"type\": \"text\", \"description\": \"Find only text about outdoor activities\"},\n",
    "    {\"query\": \"Nova model\", \"type\": \"all\", \"description\": \"Find content about Nova AI model\"}\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Testing Multimodal Search with Different Scenarios\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, test in enumerate(test_queries, 1):\n",
    "    print(f\"\\nğŸ“ Test {i}/{len(test_queries)}: {test['description']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        results = multimodal_search(test[\"query\"], test[\"type\"], top_k=3)\n",
    "        display_search_results(test[\"query\"], results, show_details=False)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in test {i}: {str(e)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Enhanced Tool Calling with Nova\n",
    "\n",
    "Now let's integrate our multimodal search with Nova's tool calling capabilities. This allows Nova to intelligently decide when and how to search for content.\n",
    "\n",
    "**How Tool Calling Works:**\n",
    "1. **User asks a question** â†’ \"Show me images of boots\"\n",
    "2. **Nova analyzes the request** â†’ Determines it needs to search for images\n",
    "3. **Nova calls our search tool** â†’ `image_search(query=\"boots\")`\n",
    "4. **We execute the tool** â†’ Actually perform the search\n",
    "5. **Nova gets the results** â†’ Uses search results to provide a comprehensive answer\n",
    "\n",
    "**Benefits:**\n",
    "- Nova decides which tool to use\n",
    "- Automatic parameter extraction\n",
    "- Intelligent response generation\n",
    "- Natural conversation flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool execution functions that Nova can call\n",
    "def execute_multimodal_search(query: str, content_type: str = \"all\", max_results: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Execute multimodal search and return formatted results for Nova\n",
    "    \n",
    "    This function is called by Nova when it wants to search for content.\n",
    "    It returns a formatted string that Nova can understand and use.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ› ï¸ Executing multimodal search tool...\")\n",
    "    print(f\"   Query: '{query}'\")\n",
    "    print(f\"   Content type: {content_type}\")\n",
    "    print(f\"   Max results: {max_results}\")\n",
    "    \n",
    "    results = multimodal_search(query, content_type, max_results)\n",
    "    \n",
    "    if not results:\n",
    "        return f\"No results found for '{query}' in {content_type} content.\"\n",
    "    \n",
    "    # Format results for Nova to understand\n",
    "    response_parts = [f\"Found {len(results)} results for '{query}':\"]\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        metadata = result.get(\"metadata\", {})\n",
    "        content_type_result = metadata.get(\"type\", \"unknown\")\n",
    "        content = metadata.get(\"content\", \"N/A\")\n",
    "        category = metadata.get(\"category\", \"general\")\n",
    "        similarity = 1 - result.get(\"distance\", 0)\n",
    "        \n",
    "        response_parts.append(\n",
    "            f\"{i}. [{content_type_result.upper()}] {content} \"\n",
    "            f\"(Category: {category}, Similarity: {similarity:.3f})\"\n",
    "        )\n",
    "    \n",
    "    formatted_response = \"\\n\".join(response_parts)\n",
    "    print(f\"\\nğŸ“Š Tool execution complete. Returning {len(results)} results to Nova.\")\n",
    "    \n",
    "    return formatted_response\n",
    "\n",
    "def execute_image_search(query: str, max_results: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Execute image-specific search - specialized tool for finding images\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ› ï¸ Executing image search tool...\")\n",
    "    print(f\"   Query: '{query}'\")\n",
    "    print(f\"   Max results: {max_results}\")\n",
    "    \n",
    "    return execute_multimodal_search(query, \"image\", max_results)\n",
    "\n",
    "print(\"ğŸ› ï¸ Tool execution functions ready for Nova!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Nova tool calling with actual tool execution\n",
    "def call_nova_with_multimodal_tools(user_message: str):\n",
    "    \"\"\"\n",
    "    Call Nova with multimodal search capabilities and execute tools when requested\n",
    "    \n",
    "    This function implements a complete conversation loop:\n",
    "    1. Send user message to Nova\n",
    "    2. Check if Nova wants to use tools\n",
    "    3. Execute requested tools\n",
    "    4. Send tool results back to Nova\n",
    "    5. Get Nova's final response\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"ğŸ¤– Starting conversation with Nova...\")\n",
    "    print(f\"ğŸ‘¤ User: {user_message}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Define tools that Nova can use\n",
    "    tool_definitions = [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"multimodal_search\",\n",
    "                \"description\": \"Search across text and image content using semantic similarity. Use this when users ask to find, search, or look for content.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Search query for finding relevant content\"\n",
    "                            },\n",
    "                            \"content_type\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Type of content to search: 'all' for everything, 'text' for text only, 'image' for images only\",\n",
    "                                \"enum\": [\"all\", \"text\", \"image\"]\n",
    "                            },\n",
    "                            \"max_results\": {\n",
    "                                \"type\": \"integer\",\n",
    "                                \"description\": \"Maximum number of results to return (1-10)\",\n",
    "                                \"minimum\": 1,\n",
    "                                \"maximum\": 10\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"query\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"image_search\",\n",
    "                \"description\": \"Search specifically for images using text queries. Use this when users specifically ask for images, photos, or pictures.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Text query to find relevant images\"\n",
    "                            },\n",
    "                            \"max_results\": {\n",
    "                                \"type\": \"integer\",\n",
    "                                \"description\": \"Maximum number of images to return (1-5)\",\n",
    "                                \"minimum\": 1,\n",
    "                                \"maximum\": 5\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"query\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Start conversation with Nova\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": user_message}]}]\n",
    "    \n",
    "    # Conversation loop - continue until Nova doesn't need more tools\n",
    "    conversation_step = 1\n",
    "    while True:\n",
    "        print(f\"\\nğŸ”„ Conversation Step {conversation_step}\")\n",
    "        \n",
    "        # Send request to Nova\n",
    "        request = {\n",
    "            \"modelId\": NOVA_MODEL_ID,\n",
    "            \"messages\": messages,\n",
    "            \"toolConfig\": {\"tools\": tool_definitions},\n",
    "            \"additionalModelRequestFields\":{'reasoningConfig': {'type': 'enabled', 'maxReasoningEffort': 'high'}}\n",
    "        }\n",
    "        \n",
    "        response = bedrock.converse(**request)\n",
    "        \n",
    "        # Add Nova's response to conversation history\n",
    "        messages.append(response[\"output\"][\"message\"])\n",
    "        \n",
    "        # Check if Nova wants to use tools\n",
    "        tool_requests = []\n",
    "        for content in response[\"output\"][\"message\"][\"content\"]:\n",
    "            if \"toolUse\" in content:\n",
    "                tool_requests.append(content[\"toolUse\"])\n",
    "            elif 'reasoningContent' in content:\n",
    "                print(\"Reasoning Content :\")\n",
    "                print(content['reasoningContent']['reasoningText']['text'])\n",
    "        \n",
    "        if not tool_requests:\n",
    "            # No tools requested - Nova has the final answer\n",
    "            print(\"\\nğŸ¤– Nova's Response:\")\n",
    "            for content in response[\"output\"][\"message\"][\"content\"]:\n",
    "                if \"text\" in content:\n",
    "                    print(content[\"text\"])\n",
    "            break\n",
    "        \n",
    "        # Execute requested tools\n",
    "        print(f\"\\nğŸ› ï¸ Nova requested {len(tool_requests)} tool(s)\")\n",
    "        tool_results = []\n",
    "        \n",
    "        for tool_request in tool_requests:\n",
    "            tool_name = tool_request[\"name\"]\n",
    "            tool_input = tool_request[\"input\"]\n",
    "            tool_id = tool_request[\"toolUseId\"]\n",
    "            \n",
    "            print(f\"\\nğŸ”§ Executing tool: {tool_name}\")\n",
    "            print(f\"ğŸ“ Parameters: {tool_input}\")\n",
    "            \n",
    "            # Execute the appropriate tool\n",
    "            if tool_name == \"multimodal_search\":\n",
    "                result = execute_multimodal_search(\n",
    "                    tool_input[\"query\"],\n",
    "                    tool_input.get(\"content_type\", \"all\"),\n",
    "                    tool_input.get(\"max_results\", 5)\n",
    "                )\n",
    "            elif tool_name == \"image_search\":\n",
    "                result = execute_image_search(\n",
    "                    tool_input[\"query\"],\n",
    "                    tool_input.get(\"max_results\", 3)\n",
    "                )\n",
    "            else:\n",
    "                result = f\"Unknown tool: {tool_name}\"\n",
    "            \n",
    "            print(f\"\\nğŸ“Š Tool Result Preview:\")\n",
    "            print(f\"{result[:200]}{'...' if len(result) > 200 else ''}\")\n",
    "            \n",
    "            # Format tool result for Nova\n",
    "            tool_results.append({\n",
    "                \"toolResult\": {\n",
    "                    \"toolUseId\": tool_id,\n",
    "                    \"content\": [{\"text\": result}]\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # Send tool results back to Nova\n",
    "        messages.append({\"role\": \"user\", \"content\": tool_results})\n",
    "        conversation_step += 1\n",
    "        \n",
    "        # Safety check to prevent infinite loops\n",
    "        if conversation_step > 5:\n",
    "            print(\"\\nâš ï¸ Conversation limit reached. Ending conversation.\")\n",
    "            break\n",
    "\n",
    "print(\"ğŸ¤– Enhanced Nova tool calling system ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Test Your Multimodal AI Assistant\n",
    "\n",
    "Time to see your creation in action! Try asking Nova questions that require searching through your content.\n",
    "\n",
    "**Great Test Queries:**\n",
    "- \"Show me images of boots\" â†’ Tests image search\n",
    "- \"Find content about running shoes\" â†’ Tests multimodal search\n",
    "- \"What outdoor footwear do you have?\" â†’ Tests semantic understanding\n",
    "- \"Tell me about Nova's capabilities\" â†’ Tests text search\n",
    "\n",
    "**What to Watch For:**\n",
    "- Nova deciding which tool to use\n",
    "- Tool execution with parameters\n",
    "- Search results being returned\n",
    "- Nova's intelligent response using the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries for the workshop\n",
    "workshop_queries = [\n",
    "    \"Show me houses with car\",\n",
    "    \"What outdoor footwear do you have?\",\n",
    "    \"Tell me about Nova's capabilities\",\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Testing Your Multimodal AI Assistant\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nWatch how Nova intelligently decides which tools to use!\")\n",
    "print(\"Each test demonstrates different aspects of multimodal search.\")\n",
    "\n",
    "for i, query in enumerate(workshop_queries, 1):\n",
    "    print(f\"\\n\\nğŸ“ Test {i}/{len(workshop_queries)}\")\n",
    "    print(f\"ğŸ¯ Query: '{query}'\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    try:\n",
    "        call_nova_with_multimodal_tools(query)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in test {i}: {str(e)}\")\n",
    "        print(\"This might be due to API limits or configuration issues.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "    # Add a small pause between tests for readability\n",
    "    import time\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\nğŸ‰ Testing complete! Your multimodal AI assistant is working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Workshop Summary\n",
    "\n",
    "Congratulations! You've successfully built a complete multimodal RAG system with Amazon Nova. Here's what you accomplished:\n",
    "\n",
    "### âœ… What You Built:\n",
    "\n",
    "1. **ğŸ¨ Multimodal Embeddings**: Used Nova to create unified embeddings for text and images\n",
    "2. **ğŸ“¦ Vector Storage**: Set up S3 Vectors for efficient similarity search\n",
    "3. **ğŸ” Cross-Modal Search**: Enabled searching images with text and vice versa\n",
    "4. **ğŸ› ï¸ Tool Integration**: Connected Nova with your search capabilities\n",
    "5. **ğŸ¤– AI Assistant**: Created an intelligent system that can understand and search multimodal content\n",
    "\n",
    "### ğŸš€ Key Concepts Learned:\n",
    "\n",
    "- **ğŸ“Š Embeddings**: Numerical representations that capture semantic meaning\n",
    "- **ğŸ”„ Cross-Modal Search**: Finding related content across different media types\n",
    "- **ğŸ“ Vector Similarity**: Using mathematical distance to find similar content\n",
    "- **ğŸ› ï¸ Tool Calling**: Enabling AI models to use external functions\n",
    "- **ğŸ­ Multimodal AI**: Systems that understand multiple types of content\n",
    "\n",
    "\n",
    "Great job completing this workshop! ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§¹ Cleanup (Optional)\n",
    "\n",
    "When you're done experimenting, you can clean up the AWS resources to avoid charges.\n",
    "\n",
    "**What gets cleaned up:**\n",
    "- S3 Vectors bucket and index\n",
    "- All stored embeddings\n",
    "- Search infrastructure\n",
    "\n",
    "**Note**: This is permanent! You'll need to re-run the workshop to recreate everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_workshop_resources():\n",
    "    \"\"\"\n",
    "    Clean up AWS resources created during the workshop\n",
    "    \"\"\"\n",
    "    print(\"ğŸ§¹ Starting workshop cleanup...\")\n",
    "    print(\"âš ï¸ This will permanently delete all workshop resources!\")\n",
    "    \n",
    "    try:\n",
    "        # Delete the vector index first\n",
    "        print(\"\\n1ï¸âƒ£ Deleting vector index...\")\n",
    "        s3vectors.delete_index(\n",
    "            vectorBucketName=VECTOR_BUCKET,\n",
    "            indexName=INDEX_NAME\n",
    "        )\n",
    "        print(f\"   âœ… Deleted index: {INDEX_NAME}\")\n",
    "        \n",
    "        # Delete the vector bucket\n",
    "        print(\"\\n2ï¸âƒ£ Deleting vector bucket...\")\n",
    "        s3vectors.delete_vector_bucket(vectorBucketName=VECTOR_BUCKET)\n",
    "        print(f\"   âœ… Deleted bucket: {VECTOR_BUCKET}\")\n",
    "        \n",
    "        print(\"\\nğŸ‰ Cleanup completed successfully!\")\n",
    "        print(\"\\nğŸ“‹ Resources that were cleaned up:\")\n",
    "        print(f\"   ğŸ“¦ Vector bucket: {VECTOR_BUCKET}\")\n",
    "        print(f\"   ğŸ” Vector index: {INDEX_NAME}\")\n",
    "        print(f\"   ğŸ¨ All stored embeddings ({successful_embeddings} items)\")\n",
    "        print(f\"   ğŸ’¾ Search infrastructure\")\n",
    "        \n",
    "        print(\"\\nğŸ’¡ To use the system again, re-run the entire workshop notebook.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during cleanup: {str(e)}\")\n",
    "        print(\"\\nğŸ”§ Manual cleanup may be required:\")\n",
    "        print(f\"   - Delete S3 Vectors bucket: {VECTOR_BUCKET}\")\n",
    "        print(f\"   - Delete vector index: {INDEX_NAME}\")\n",
    "        print(\"   - Check AWS Console for any remaining resources\")\n",
    "\n",
    "# Uncomment the line below to run cleanup\n",
    "cleanup_workshop_resources()\n",
    "\n",
    "print(\"ğŸ’¡ To clean up resources, uncomment and run: cleanup_workshop_resources()\")\n",
    "print(\"âš ï¸ Warning: This will permanently delete all workshop data!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:agent]",
   "language": "python",
   "name": "conda-env-agent-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
